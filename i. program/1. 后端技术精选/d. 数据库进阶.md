# 数据库进阶


- [数据库进阶](#数据库进阶)
  - [一、索引原理](#一索引原理)
    - [1.1、为什么使用索引？](#11为什么使用索引)
    - [1.2、mysql的索引类型](#12mysql的索引类型)
    - [1.3、索引方法](#13索引方法)
    - [1.4、InnoDB一棵B+树可以存放多少行数据？](#14innodb一棵b树可以存放多少行数据)
    - [1.5、聚集索引 && 非聚集索引 && 覆盖索引](#15聚集索引--非聚集索引--覆盖索引)
  - [二、B树详解](#二b树详解)
    - [2.1、平衡多路查找树（B-Tree）](#21平衡多路查找树b-tree)
    - [2.2、B+Tree](#22btree)
    - [2.3、b-tree和b+tree的比较](#23b-tree和btree的比较)
  - [三、SQL优化](#三sql优化)
    - [3.1、mysql的逻辑架构](#31mysql的逻辑架构)
    - [3.2、数据类型优化](#32数据类型优化)
    - [3.3、索引优化](#33索引优化)
    - [3.4、查询性能优化](#34查询性能优化)
    - [3.5、sql执行分析explain](#35sql执行分析explain)
    - [3.6、查询SQL执行记录](#36查询sql执行记录)
  - [五、数据库的锁](#五数据库的锁)
    - [5.1、锁的类型](#51锁的类型)
    - [5.2、行级锁](#52行级锁)
    - [5.3、表级锁](#53表级锁)
    - [5.4、页级锁](#54页级锁)
    - [5.5、意向锁](#55意向锁)
    - [5.6、死锁](#56死锁)
    - [5.6、死锁分析](#56死锁分析)
  - [六、mysql的高可用方案](#六mysql的高可用方案)
    - [5.1、读写分离](#51读写分离)
    - [5.2、双写一致性问题](#52双写一致性问题)
  - [七、mysql问题排查](#七mysql问题排查)
  - [八、other question](#八other-question)
    - [8.1、三范式](#81三范式)
    - [8.2、顺序自增主键造成的坏影响](#82顺序自增主键造成的坏影响)
  - [九、DB对比](#九db对比)
    - [9.1、InnoDB与MyISAM的区别](#91innodb与myisam的区别)
    - [9.2、MySQL 中，当 update 修改数据与原数据相同时会再次执行吗](#92mysql-中当-update-修改数据与原数据相同时会再次执行吗)
- [NoSql进阶](#nosql进阶)
  - [一、Redis](#一redis)
    - [1.1、Redis的基本数据结构和对象系统](#11redis的基本数据结构和对象系统)
    - [1.2、Redis持久化](#12redis持久化)
    - [1.3、集群同步机制](#13集群同步机制)
    - [1.2、Redis的IO模型](#12redis的io模型)
    - [1.3、Redis的多线程模型](#13redis的多线程模型)
    - [1.4、Redis集群的一致性算法](#14redis集群的一致性算法)
    - [1.5、Redis的高可用方案](#15redis的高可用方案)
    - [1.6、缓存和DB双写一致性问题](#16缓存和db双写一致性问题)
    - [1.7、延时队列](#17延时队列)
  - [二、ElasticSearch](#二elasticsearch)
  - [三、MongoDB](#三mongodb)
  - [参考文章](#参考文章)
      - [关系数据库](#关系数据库)
      - [nosql数据库](#nosql数据库)
    

## 一、索引原理

### 1.1、为什么使用索引？
  - 索引可以把随机IO变成顺序IO
  - 索引能极大的减少存储引擎需要扫描的数据量
  - 索引可以帮助我们在进行分组、排序等操作时，避免使用临时表

### 1.2、mysql的索引类型

InnoDB共有五种索引类型，基本都是基于b+tree

- primary——主键索引
- unique——主键索引
- key——普通索引
- fulltext——全文索引
- 组合索引

### 1.3、索引方法
- B-Tree，
- B+Tree，
- R-Tree,
- Hash，
- bitmap
- REVERSE
- 函数索引
- 倒排索引


### 1.4、InnoDB一棵B+树可以存放多少行数据？


- __mysql的最小存储单元__

  - 我们都知道计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。




- __一颗B+数的最大存储数量__

  - nnoDB存储引擎中默认每个页的大小为16KB，可通过参数innodb_page_size将页的大小设置为4K、8K、16K，在MySQL中可通过如下命令查看页的大小：
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200519145257.png)

  - InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为〖10〗^3）。

  - 也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录。

  - 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2~4层。


### 1.5、聚集索引 && 非聚集索引 && 覆盖索引
![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200525112637.png)

- __聚集索引__
  - 叶子节点存储的是完整的数据（整行数据）
  - innodb中一张表只能有一个聚集索引，一般为主键索引，如果没有主键，会选择一个非空唯一的索引代替，还没有的话就隐式的定义一个主键来作为聚蔟索引
  - 由于数据存储在叶子节点上，所以物理存储按照索引排序

- __非聚集索引（辅助索引）__
  - 叶子节点中存储的是索引的列信息和主键信息
  - 当通过非聚集索引来寻找数据时，innodb存储引擎会遍历非聚集索引获得指向主键索引的指针，然后再通过主键索引来找到一个完整的行记录
  - 一张表中可以有多个非聚集索引，一般为普通索引都是非聚集索引
  - 由于叶子节点存储的是行指针，所以物理存储不按照索引排序

- __InnoDB 的辅助索引叶子节点为什么不直接保存的记录地址而要存主键键值__
  
- 如果存储的是记录地址的话，如果数据记录发生了页裂变导致数据地址变了，那辅助索引也要更新，对于这种情况来说存储主键更好
  
- __覆盖索引__
  - 覆盖索引也就是平时所说的复合索引或者多字段索引查询，一个索引指定两个字段， 那么这个两个字段的内容都会被同步至索引的叶节点当中。
    ```sql
    create index index_colA_colB on tab_user(colA, colB);
    select colB from tab_user where colA = '123';
    ```
  - 如上所示，索引子节点中存储了 colA和colB的值，通过索引可以直接获取colB的值，无需再通过主键索引查询，大大的提高了查询性能。
  - 当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。
  - 有关于复合索引，我们需要关注查询Sql条件的顺序，确保最左匹配原则有效，同时可以删除不必要的冗余索引。


## 二、B树详解


### 2.1、平衡多路查找树（B-Tree）

- __一棵m阶的B-Tree有如下特性__

  1. 每个节点最多有m个孩子。
  2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。
  3. 若根节点不是叶子节点，则至少有2个孩子
  4. 所有叶子节点都在同一层，且不包含其它关键字信息
  5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）
  6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1
  7. ki(i=1,…n)为关键字，且关键字升序排序。
  8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)

- __B-Tree的结构__
  B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree：
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200519145858.png)

  - 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。以根节点为例，关键字为17和35，P1指针指向的子树的数据范围为小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。

  - 模拟查找关键字29的过程：

    1. 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】
    2. 比较关键字29在区间（17,35），找到磁盘块1的指针P2。
    3. 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】
    4. 比较关键字29在区间（26,30），找到磁盘块3的指针P2。
    5. 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】
    6. 在磁盘块8中的关键字列表中找到关键字29。
  
  - 分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。


### 2.2、B+Tree

- __为什么要升级B+Tree__

  - B+Tree是在B-Tree基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用B+Tree实现其索引结构。

  - 从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。

  - 在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。

- __B+Tree的结构__

  - 由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200519150609.png)

  - 通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对B+Tree进行两种查找运算：
    1. 对于主键的范围查找和分页查找
    2. 从根节点开始，进行随机查找

  - mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

  - 数据库中的B+Tree索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。上面的B+Tree示例图在数据库中的实现即为聚集索引，聚集索引的B+Tree中的叶子节点存放的是整张表的行记录数据。辅助索引与聚集索引的区别在于辅助索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚集索引键，即主键。当通过辅助索引来查询数据时，InnoDB存储引擎会遍历辅助索引找到主键，然后再通过主键在聚集索引中找到完整的行记录数据。


### 2.3、b-tree和b+tree的比较
  - __B树，它的特点是：__
      - 不再是二叉搜索，而是m叉搜索；
      - 叶子节点，非叶子节点，都存储数据；
      - 中序遍历，可以获得所有节点；
  - __B+树的特点是：__
    - 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上；
    - 叶子之间，增加了链表，获取所有节点，不再需要中序遍历；
  - __以上改进让B+树比B树有更优的特性：__

    - 范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯（范围查询在SQL中用得很多，这是B+树比B树最大的优势）；
    - 叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储；
    - 非叶子节点，不存储实际记录，而只存储记录的KEY的话，那么在相同内存的情况下，B+树能够存储更多索引；

## 三、SQL优化

### 3.1、mysql的逻辑架构
- __架构图__
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200616170723.png)
  - 最上层连接处理
    - 一般由第三方的客户端来实现，连接处理、授权认证、安全等等

  - 第二层架构
    - mysql的核心功能都集中在此、包括查询解析、分析、优化、缓存以及所有内置函数等

  - 第三层架构
    - 存储引擎层，负责mysql中数据的存储和提取

- __sql的执行流程__
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200616172316.png)

### 3.2、数据类型优化
- 更小的通常更好
- 简单就好
- 尽量避免null

### 3.3、索引优化
- __自定义hash索引__
  - 在B-Tree基础上创建一个伪哈希索引。这和真正的哈希索引不是一回事因为还是使用B-Tree进行查找，但是它使用哈希值而不是键本身进行索引査找。需要做的就是在査询的 WHERE子句中手动指定使用哈希函数
  - 常见场景如对URL进行定位查询
    - 由于url是varchar类型，字段本身的存储空间和索引占用的存储空间都比较大,如果加一个crc32_url列，并且只在这个列上加索引，索引空间就会小很多,并使用整型加速查询速度避免字符串url全表扫描
    - CRC32函数返回值的范围是0-4294967296（2的32次方减1), 很容易产生碰撞，所以需要查询的时候再加上真实数据的条件，也可以自定义crc64() ，来减少hash碰撞
      ```sql
      SELECT id FROM table_url WHERE url="http://mw.mysql.com";
      SELECT id FROM table_url WHERE url = "http://www.mysql.com" AND url_crc=crc32(http://www.mysql.com)
      ```
  - 可以通过创建触发器来维护hash索引

- __前缀索引__
  - 有时候需要素引很长的字符列，这会让索引变得大且慢。可以使用前缀索引的方式，来减少索引体积
  - 前缀索引会降低索引的选择性。索引的选择性 = 不重复的索引值/数据表的记录总数，索引选择性越高，性能也就越好。
    ```sql
    //前缀索引创建
    ALTER TABLE sakilacity demo ADD KEY(city(7));
    ```

- __多列索引之索引合并策略__
  - where 中可能有多个条件(或者join)涉及到多个字段，它们之间进行 AND 或者 OR，那么此时就有可能会使用到 index merge 技术。index merge 技术如果简单的说就是：对多个索引分别进行条件扫描，然后将它们各自的结果进行合并(intersect/union)

  - MySQL5.0之前，一个表一次只能使用一个索引，无法同时使用多个索引分别进行条件扫描。但是从5.1开始，引入了 index merge 优化技术，对同一个表可以使用多个索引分别进行条件扫描

  - 当出现服务器对多个索引做相交操作时（通常有多个AND条件），通常意味着需要个包含所有相关列的组合索引，而不是多个独立的单列索引。
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200617180715.png)

- __选择合适的索引列顺序__
  - 在组合索引中，最好把过滤权重最高的条件放到前列，来保证索引能够过滤掉绝大部分数据，提高性能


- __聚蔟索引（主键）的合理设计__
  - 聚蔟索引的叶子节点存储了数据行的完整数据，innodb的主键被默认设置为聚蔟索引，每次查询非聚蔟索引的时候，会拿到对应的主键，再通过聚蔟索引来查询完整行数据
  - 所以一定要保证聚蔟索引的性能，最后设置为自增的序列，防止页
  - 而且更新聚蔟索引的代价也很高，数据库会强制把每个更新的行移动到新的位置，可能导致页分裂的问题（当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作页分裂会导致表占用更多的磁盘空间）

- __覆盖索引__
  - 如果一个索引包含（或者说覆盖）所有需要査询的字段的值，没有必要再回表查询，我们就称之为“覆盖索引”


### 3.4、查询性能优化


### 3.5、sql执行分析explain

大部分的性能分析都需要使用到该命令，可以用来查看SQL语句的执行效果，可以帮助选择更好地索引和优化语句。

- __使用方法__
  explain + SQL语句
  ```sql
  explain select * from table_name where column_one = '123'
  ```
- __参数解析__
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200525144440.png)
  - select_type ：表示 select 类型
    - simple：简单表，及不使用表连接或者子查询
    - primary：主查询，即外层的查询
    - union：union 中的第二个或后面的查询语句
    - subquery： 子查询中的第一个 select
  - type：表示 mysql 在表中找到所需行的方式，或者叫访问类型
    - 常见类型性能由差到最好依次是：all、index、range、ref、eq_ref、const，system、null
    - type=ALL，全表扫描
    - type=index, 索引全扫描
    - type=range,索引范围扫描
    - type=const/system,单表中最多有一个匹配行，查起来非常迅速
    - type=null, mysql 不用访问表或者索引，直接就能够得到结果

  - possible_keys : 表示查询时可能使用的索引。
  - key ：表示实际使用索引
  - key-len : 使用到索引字段的长度。
  - rows ： 扫描行的数量
  - extra：执行情况的说明和描述，包含不适合在其他列中显示但是对执行计划非常重要的额外信息。



### 3.6、查询SQL执行记录

- __查询日志功能是否开启__

  ```sql
  show variables LIKE 'general%';
  ```
  - general_log:日志记录功能是否开启，默认为OFF
  - general_log_file:日志存放路径

- __开启日志功能__
    ```sql
  set GLOBAL general_log = 'ON';
  ```

- __在指定路径查看SQL记录__



### 3.7、常规sql优化
- __加索引__

- __避免返回不必要的数据__

- __适当分批量进行__

- __优化sql结构__

- __优化limit分页__
  - 当偏移量最大的时候，查询效率就会越低，因为Mysql并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的
  - 解决方案
    ```sql
    //方案一 ：返回上次查询的最大记录(偏移量)
    select id，name from employee where id>10000 limit 10.

    //方案二：order by + 索引
    select id，name from employee order by id  limit 10000，10

    //方案三：在业务允许的情况下限制页数：
    ```
- __分库分表__

- __读写分离__

## 四、事务

### 4.1、什么是事务
> 数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作；事务是一组不可再分割的操作集合（工作逻辑单元）

> 事务最经典常用的栗子可能就是转账：一个账户少钱了，哪另一个账户肯定要多钱，李永龙说过，亏本的买卖咱可不干，吃亏了不高兴！所以，少钱和多钱这两个操作，要么同时成功，要么同时失败！

- __MySQL中如何开启事务？__
  - 手工开启：begin/start transaction
  - 事务提交或回滚：commit/rollback
  - 设定事务是否自动开启：set session autocommit = on/off

### 4.2、事务的特性

事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作， 这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行 。 事务是一个不可分割的工作逻辑单元事务必须具备以下四个属性，简称 ACID 属性：

- A（Atomicity）原子性
  - 最小的工作单元，要么一起成功，要么一起失败

- C（Consistency）一致性
  - 一致性也称作是完整性，就是说事务的执行不能破坏数据库的一致性，一个事务在执行后，数据库必须从一个状态转变为另一个状态

- I（Isolation）隔离性
  - 并发的事务相互隔离，互不干扰

- D（Durability）持久性
  - 持久性是指事务一旦提交，对数据库的状态就应该被永久保存




### 4.3、事务的隔离级别 & 对应的问题


- __事务隔离级别：__
    ANSI/ISO SQL标准定义了4中事务隔离级别：
    - __未提交读（read uncommitted）：__ Read Uncommitted是隔离级别最低的一种事务级别。在这种隔离级别下，已发生脏读（Dirty Read）
    - __提交读（read committed）：__ 在Read Committed隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题
    - __重复读（repeatable read）：__ 在Repeatable Read隔离级别下，一个事务可能会遇到幻读（Phantom Read）的问题。
    - __串行读（serializable）：__ Serializable是最严格的隔离级别。在Serializable隔离级别下，所有事务按照次序依次执行，因此，脏读、不可重复读、幻读都不会出现。虽然Serializable隔离级别下的事务具有最高的安全性，但是，由于事务是串行执行，所以效率会大大下降，应用程序的性能会急剧降低。如果没有特别重要的情景，一般都不会使用Serializable隔离级别。
    - 不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差，4种事务隔离级别分别表现的现象如下表：

      |隔离级别         |脏读|不可重复读|幻读|
      |----------------|----|-------|------|
      |read uncommitted|允许|允许    |允许  |
      |read committed  |    |允许    |允许  |
      |repeatable read |    |        |允许 |
      |serializable    |    |        |     |

 - __事务隔离导致的问题__

    - __脏读（dirty read）__
      - Read Uncommitted是隔离级别最低的一种事务级别。在这种隔离级别下，一个事务会读到另一个事务更新后但未提交的数据，如果另一个事务回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read）。
      - __简单来说就是读到别的事务没有提交的数据。__


    - __不可重复读（nonrepeatable read）__
      - 在Read Committed隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题。不可重复读是指，两个相同的查询返回了不同的结果，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。
      - __简单来说先前读取的数据，被别的事务改变了，再读就跟原来不一样了。__
    
    - __幻读（phantom read）__
      - MySql默认的隔离级别为Repeatable Read（重复读），因此只会出现幻读的情况。幻读是指，在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功（或者插入该记录出现主键冲突），并且，再次读取同一条记录，它就神奇地出现了。
      - 简单来说就是第一次读的时候发现什么都没有，另一个事务偷偷放了东西进去，再去访问的时候惊讶地居然发现有东西了
    
    - __幻读和不可重复读的区别：__
      - 幻读中事务二的数据操作仅仅是插入和删除，读取的记录数量前后不一致。而不可重复读中是修改数据，导致同一个查询返回了不同的结果


- __如何解决幻读__

  1. 设置事务隔离级别为串行读（效率低下，太low）
  2. 使用间隙锁（解决当前读情况下的幻读问题）
  3. InnoDB的MVCC机制来解决（MVCC只能解决快照读情况下的幻读问题）



### 4.4、MVCC机制

- __什么是MVCC__
  
> MVCC，Multi-Version Concurrency Control，多版本并发控制。MVCC 是一种乐观锁的实现方法，它是通过 一种 可见性算法 来实现数据库并发控制。
  
- __MVCC前奏知识__

  - __undoLog__: 事务的回滚日志，是 可见性算法 的非常重要的部分，分为两类。

    - insert undo log：事务在插入新记录产生的undo log，当事务提交之后可以直接丢弃
    - update undo log：事务在进行 update 或者 delete 的时候产生的 undo log，在快照读的时候还是需要的，所以不能直接删除，只有当系统没有比这个log更早的read-view了的时候才能删除。ps：所以长事务会产生很多老的视图导致undo log无法删除 大量占用存储空间。

  - __快照读__：读取的只是当前事务的可见版本，不用加锁。而你只要记住 简单的 select 操作就是快照读(select * from table where id = xxx)。


  - __当前读__: 读取的是记录数据的最新版本，显示加锁的都是当前读。
    ```sql
    select * from account where id>2 lock in share mode;
    select * from  account where id>2 for update;
    ```
  - __read-view__
    - Read View就是事务执行快照读时，产生的读视图
    - 事务执行快照读时，会生成数据库系统当前的一个快照，记录当前系统中还有哪些活跃的读写事务，把它们放到一个列表里
    - Read View主要是用来做可见性判断的，即判断当前事务可见哪个版本的数据
    - 为了下面方便讨论Read View可见性规则，先定义几个变量
      ```xml
      m_ids:当前系统中那些活跃的读写事务ID,它数据结构为一个List。
      min_limit_id:m_ids事务列表中，最小的事务ID
      max_limit_id:m_ids事务列表中，最大的事务ID
      ```

- __MVCC原理__
  - MVCC 使每个连接到数据库的读者，在某个瞬间看到的是数据库的一个快照，写者写操作造成的变化在写操作完成之前（或者数据库事务提交之前）对于其他的读者来说是不可见的，它的实现依赖于 __隐式字段、undo日志、快照读&当前读、Read View__。
  - MVCC 使用了“三个隐藏字段”来实现版本并发控制
    - RowID：隐藏的自增ID，当建表没有指定主键，InnoDB会使用该RowID创建一个聚簇索引。
    - DB_TRX_ID：最近修改（更新/删除/插入）该记录的事务ID。
    - DB_ROLL_PTR：回滚指针，指向这条记录的上一个版本。

- __MVCC可见性流程__
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200527164027.png)
  - 如果被访问版本的 trx_id 小于 m_ids 中的最小值 min_limit_id ，说明生成该版本的事务在  ReadView  生成前就已经提交了，所以该版本可以被当前事务访问。
  - 如果被访问版本的 trx_id 大于 m_ids 列表中的最大值max_limit_id ，说明生成该版本的事务在生成  ReadView  后才生成，所以该版本不可以被当前事务访问。需要根据  Undo Log  链找到前一个版本，然后根据该版本的 DB_TRX_ID 重新判断可见性
  - 如果被访问版本的  trx_id  属性值在  m_ids  列表中最大值和最小值之间（包含），那就需要判断一下  trx_id  的值是不是在  m_ids  列表中。如果在，说明创建  ReadView  时生成该版本所属事务还是活跃的，因此该版本不可以被访问，需要查找 Undo Log 链得到上一个版本，然后根据该版本的  DB_TRX_ID  再从头计算一次可见性；如果不在，说明创建  ReadView  时生成该版本的事务已经被提交，该版本可以被访问。
  - 此时经过一系列判断我们已经得到了这条记录相对  ReadView  来说的可见结果。此时，如果这条记录的  delete_flag  为  true ，说明这条记录已被删除，不返回


### 4.5、mysql中的事务
- mysql默认采用自动提交的模式，可以通过设置来改为手动提交
  ```sql
  SET @@autocommit=0;
  SHOW VARIABLES LIKE '%autocommit%'
  ```

## 五、数据库的锁

### 5.1、锁的类型
- 行级锁
- 页级锁
- 表级锁


### 5.2、行级锁
- __行级锁的介绍__
  - 行级锁是一种排他锁，防止其他事务修改此行；在使用以下语句时， Oracle 会自动应用行级锁：
    1. INSERT、 UPDATE、 DELETE、 SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];
    2. SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新
    3. 使用 COMMIT 或 ROLLBACK 语句释放锁
  - MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

- __mysql中的行锁执行流程__
  - InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能
  - __在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议__。知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
  - __由于mysql 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但如果是使用相同的索引键，是会出现锁冲突的__
     - a. __使用相同索引键值的冲突__（由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的）
     - b. __使用不同索引键值但是同一行的冲突__（当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。）
     - c. __创建了索引，但使用的是表锁__（即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引）

- __InnoDB三种行锁__
  - Record Lock（行锁）：单个行记录上的范围
     - Record Lock总是会锁住索引记录，如果InnoDB存储引擎建立的时候没有设置任何一个索引，这时InnoDB存储引擎会使用隐式的主键来进行锁定。
     - 行锁锁定的是索引记录，而不是行数据，也就是说锁定的是key。
  - Gap Lock（间隙锁）：锁定一个范围，但不包含记录本身
    - Gap Lock在InnoDB的唯一作用就是防止其他事务的插入操作，以此防止幻读的发生。
  - Next-Key Lock（后码锁）：锁定一个范围，并且锁定记录本身 Gap Lock + Record Lock


### 5.3、表级锁

- __表锁介绍__
  - 表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分 MySQL 引擎支持。最常使用的 MYISAM 与 INNODB 都支持表级锁定。表级锁定分为 __表共享读锁（共享锁）__ 与 __表排他写锁（排它锁）__
  - MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁。
  - 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；写操作，则会阻塞其他用户对同一表的读和写操作
  - MyISAM存储引擎的表级锁中读锁和写锁是互斥的，读写操作是串行的。__那么，一个进程请求某个 MyISAM表的读锁，同时另一个进程也请求同一表的写锁，写进程先获得锁__。不仅如此，即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前！这是因为MySQL认为写请求一般比读请求要重要。这也正是MyISAM表不太适合于有大量更新操作和查询操作应用的原因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。
  - 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。
  - 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低
  - 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级
  - MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会


### 5.4、页级锁
  - 页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 BDB 支持页级锁


### 5.5、意向锁
  - __什么是意向锁__
    - 意向锁是表锁的一种，分为意向共享锁、意向排它锁。
  - __意向锁的目的__
    - 事务A锁住表中的一行（写锁）。事务B锁住整个表（写锁）但你就会发现一个很明显的问题，事务A既然锁住了某一行，其他事务就不可能修改这一行。这与”事务B锁住整个表就能修改表中的任意一行“形成了冲突。
    - 所以意向锁的目的就是 __解决表锁与之前可能存在的行锁冲突，避免为了判断表是否存在行锁而去扫描全表的系统消耗。__ 
  - __意向锁流程__
    - 当一行记录被加上共享锁的时候，会自动给表加上意向共享锁。行记录被加上排他锁的时候，会自动给表加上意向排它锁。
    - 当该表要加表共享锁的时候，会去判断是否有意向排它锁，如果有意向排它锁，就不能被加表共享锁。



### 5.6、死锁
  - MyISAM表锁是deadlock free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，当两个事务都需要获得对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。
  - 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200426113818.png)
  
  - 事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。
  
  - 当出现死锁以后，有三种策略：
    1. 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
    2. 发起死锁检测，发现死锁后，回滚持有最少行级排它锁的事务，让其他事务得以继续执行。将参数 __innodb_deadlock_detect__ 设置为 on，表示开启这个逻辑。减少死锁的主要方向，就是控制访问相同资源的并发事务量。
    3. 通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小，以及访问数据库的SQL语句，绝大部分死锁都可以避免。例如在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。

### 5.6、死锁分析

- __模拟环境__
  - 重现死锁场景
- __查看日志__
  ```sql
  SHOW ENGINE INNODB STATUS;
  ```
- __分析日志__
  - 1、找到关键词TRANSACTION
  - 2、查看正在执行的SQL
  - 3、找到正在等待锁释放(WAITING FOR THIS LOCK TO BE GRANTED)
  - 4、找到持有锁的事务(HOLDS THE LOCK)
  - 5、还原死锁过程
  - 6、排查业务代码


## 六、mysql的高可用方案


### 5.1、读写分离

- __如何实现mysql的读写分离？__
  - 就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。

- __MySQL主从复制原理的是啥？__
  1. 主库将变更写binlog日志，然后从库连接到主库之后，从库有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个中继日志中。  
  2. 着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍SQL，这样就可以保证自己跟主库的数据是一样的。

- __主从复制的关键点__
  - 这里有一个非常重要的一点，就是从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行
  - 由于从库从主库拷贝日志以及串行执行SQL的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。
  - 所以经常出现，刚写入主库的数据可能是读不到的，要过几十毫秒，甚至几百毫秒才能读取到。
  - 而且这里还有另外一个问题，就是如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了

- __主从复制数据丢失问题方案__
  - 如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了
  - 我们可以采用半同步复制即semi-sync复制来解决。
  - 指的就是主库写入binlog日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ack给主库，主库接收到至少一个从库的ack之后才会认为写操作完成了。


- __主从复制延时问题方案__
  - 产生所谓的主从延迟主要是看主库的写并发。主库的写并发达到1000QPS，从库的延时有几ms，主库的写并发达到2000QPS，从库的延时可能有几十ms
  - 一般我们可以采用并行复制的方案来解决。从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。
  - 采用分库的方案，将一个主库拆分为4个主库，每个主库的写并发就500/s，此时主从延迟可以忽略不计


### 5.2、双写一致性问题
- __概念描述：__
  - 数据库里的值和缓存中的数据不一致的现象就叫做数据库和缓存双写一致性问题
  - 在高并发的情况下很难去保证数据库和缓存的数据永远一致，我们只能去确保最终一致性。

- __plan1：给缓存设置失效时间__
    - 统一要求当缓存失效时再去数据库中查数据更新缓存

- __plan2：Cache Aside Pattern__
  - 写的时候先更新数据库，再删缓存的策略
  - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 
    标准的Pattern，facebook就是使用这种方式，具体流程如下：
    - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
    - 命中：应用程序从cache中取数据，取到后返回。
    - 更新：先把数据存到数据库中，成功后，再让缓存失效。
  - 问题：
    1. 缓存刚好失效
    2. 请求A查询数据库，得一个旧值
    3. 请求B将新值写入数据库
    4. 请求B删除缓存
    5. 请求A将查到的旧值写入缓存 ok，如果发生上述情况，确实是会发生脏数据

- __plan3：先删除缓存，再更新数据库策略__
  - 缺点：
    - 并发情况下，A删除了缓存，B进行查询，找到旧值写入缓存，A再更新DB，造成不一致问题

- __plan3升级：延迟双删__
  - 先删除缓存，再更新数据库，等待一定时间后再删除缓存
  - 缺点：
    - todo

- __最佳方案：__
  - 给缓存设置失效时间，达成最终一致性
  - Cache Aside Pattern方案



## 七、mysql问题排查


## 八、other question

### 8.1、三范式
- 第一范式：列不可再分，即列的原子性
- 第二范式：行可以唯一区分，主键约束
- 第三范式：表的非主属性不能依赖与其他表的非主属性 外键约束
且三大范式是一级一级依赖的，第二范式建立在第一范式上，第三范式建立第一第二范式上 。

### 8.2、顺序自增主键造成的坏影响
- 在高并发的情况下，innoDB按主键顺序插入可能会造成锁的竞争，主键的上界点会成为热点，所有的插入都发送在这，并发的插入很容易导致间隙锁的竞争。
- auto_increment锁机制，造成的并发锁竞争。


## 九、DB对比

### 9.1、InnoDB与MyISAM的区别
  - InnoDB支持事务，MyISAM不支持事务
  - InnoDB支持外键，MyISAM不支持外键
  - InnoDB 支持 MVCC(多版本并发控制)，MyISAM 不支持
  - InnoDB支持表、行级锁，而MyISAM支持表级锁
  - InnoDB表必须有主键，而MyISAM可以没有主键
  - InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与 MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和索引


### 9.2、MySQL 中，当 update 修改数据与原数据相同时会再次执行吗
- 在binlog_format=row和binlog_row_image=FULL时，由于MySQL 需要在 binlog 里面记录所有的字段，所以在读数据的时候就会把所有数据都读出来，那么重复数据的update不会执行

- 在binlog_format=statement和binlog_row_image=FULL时，InnoDB内部认真执行了update语句，即“把这个值修改成 (1,999)“这个操作，该加锁的加锁，该更新的更新。

- mysql复制主要有三种方式：基于SQL语句的复制(statement-based replication, SBR)，基于行的复制(row-based replication, RBR)，混合模式复制(mixed-based replication, MBR)。对应的，binlog的格式也有三种：STATEMENT，ROW，MIXED。

  - STATEMENT模式（SBR）
    > 每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题)

  - ROW模式（RBR）
    > 不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。

  - MIXED模式（MBR）
    > 以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。



# NoSql进阶

- [NoSql进阶](#nosql进阶)
  - [一、Redis](#一redis)
    - [1.1、Redis的基本数据结构和对象系统](#11redis的基本数据结构和对象系统)
    - [1.2、Redis持久化](#12redis持久化)
    - [1.3、集群同步机制](#13集群同步机制)
    - [1.2、Redis的IO模型](#12redis的io模型)
    - [1.3、Redis的多线程模型](#13redis的多线程模型)
    - [1.4、Redis集群的一致性算法](#14redis集群的一致性算法)
    - [1.5、Redis的高可用方案](#15redis的高可用方案)
    - [1.6、缓存和DB双写一致性问题](#16缓存和db双写一致性问题)
    - [1.7、延时队列](#17延时队列)
  - [二、ElasticSearch](#二elasticsearch)
  - [三、MongoDB](#三mongodb)
  - [四、参考文章](#四参考文章)


## 一、Redis

### 1.1、Redis的基本数据结构和对象系统


### 1.2、Redis持久化

- __RDB：__ 
  - RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化

- __AOF：__ 
  - AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的binlog

### 1.3、集群同步机制

- Redis的主从模式采用的是RDB文件同步的方式，因为Redis的服务端，数据量有可能非常的大，所以从性能考虑，没有采用AOF快照来同步。

- __全量过程大概如下：__
  1. 从机上线，主动链接主机，发送SYNC命令
  2. 主机接到命令后，执行BGSAVE命令，生成RDB文件
  3. 主机向从机发送RDB文件，开始同步数据
  4. 同步之后，主机将最近的更新，采用命令的形式同步到从机上面。

- __增量过程：__
  1. 当从机断线重连之后，会发送PSYNC,要求增量同步，并包括一个offset
  2. 主机根据offset的位置，对之后的数据进行一次增量同步，到从机上面（offset是由主机和从机共同维护的，相当于一个乐观锁，描述了两方的版本差异）

- __决定能否增量同步的主要因素：__
  1. 是否具备偏移量，与主机进行对比
  2. 主服务器的复制积压缓冲区（Replication backlog）
       - Redis每分钟都会处理很多的数据，不可能一直把更新的操作存起来，等待从机上线在传输，AOF也不是都在内存中一直保存，所以Redis有一个缓冲区，采用队列的模式来存储这些写操作。

       - 所有的更新操作以队列的形式放入里面，内存大小默认是1MB，超过1MB之后，前面进入队列的写操作就会被移除。

       - 所以当从机上线之后，如果offset与主机版本差距的内容还在缓冲区内，则可以从缓冲区进行增量同步。否则依然还是全量同步（RDB），这里就好比你的机器宕机了一天，在上线，你不能要求我把这一天的数据都给你吧，你直接全量同步得了。

       - 这里我就想到了一个问题，如果我们反复对Redis更新特别大的K-V的话，超过1M，会使得这个缓冲区失效，因为每次的更新都超过这个缓冲区大小了，所以同步操作对于从机来说，都是全量同步，如果太频繁的话，则会产生很大的问题。

       - 这个缓冲区的大小也是可以设置调整的饿，可以根据需求配置
  3. 从服务器的ID
     - Redis有一个Slot的概念，每个机器负责一部分的Key，所以如果你之前不是我的从机，那你内存内的数据肯定都不是我的值，就不能只看offset了，还要看一下你之前是不是我的从机，这里主机会维护从机的唯一ID，来校验。


### 1.2、Redis的IO模型

- 多路复用IO模型


### 1.3、Redis的多线程模型

- __redis6.0之后加入了多线程模型__
- __初始化三类线程__
  - 这三类线程被认为是后台执行.不影响主线程

  1. BIO_CLOSE_FILE . 关闭重写之前的aof文件.
  2. BIO_AOF_FSYNC . 定时刷新数据到磁盘上.
  3. BIO_LAZY_FREE . 惰性删除过期时间数据


### 1.4、Redis集群的一致性算法
- __Hash槽算法__
  - 哈希槽是在redis cluster集群方案中采用的，redis cluster集群没有采用一致性哈希方案，而是采用数据分片中的哈希槽来进行数据存储与读取的。

  - Redis 集群中内置了2^14（16384）个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点

- __Hash槽的扩容流程__
  

- __为什么redis集群的最大槽数是16384个？__
  - 在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，在发送心跳包时使用char进行bitmap压缩后是2k（2 * 8 (8 bit) * 1024(1k) = 2K），也就是说使用2k的空间创建了16k的槽数
  - 一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择

- __Hash槽和一致性Hash的区别__
  - __redis中数据是存储在槽上，槽又存储到节点上，每次新增，删除节点时可以直接移动槽，而不需要像一致性hash那样重新计算部分数据的hash值再进行迁移。__
  - 一致性hash是一个0-2^32的闭合圆，Hash槽是一个2^14（16384）个槽组成的一个个槽区，
  - 一致性Hash存在hash倾斜的问题，而Hash槽是均匀分配的，
  - Hash槽key的定位规则是根据CRC-16(key)%16384的值来判断属于哪个槽区，从而判断该key属于哪个节点，而一致性哈希是根据hash(key)的值来顺时针找第一个hash(ip)的节点，从而确定key存储在哪个节点。
  - 一致性哈希是创建虚拟节点来实现节点宕机后的数据转移并保证数据的安全性和集群的可用性的。redis cluster是采用master节点有多个slave节点机制来保证数据的完整性的,master节点写入数据，slave节点同步数据。当master节点挂机后，slave节点会通过选举机制选举出一个节点变成master节点，实现高可用

### 1.5、Redis的高可用方案

- __主从模式：__
  - 一主多从的结构部署，主节点提供读写操作，从节点提供读的操作，主节点数据自动同步至从节点。可以有效的解决读多写少的情景，把读请求均摊到从节点上。
  - 缺点：
    - 不能自动进行故障转移，主备切换，需要手动操作或者自己编写客户端脚本进行处理。
    - 主库的写能力和存储能力受到单机的限制，
    - 每个从库都保存的主库完整数据，无法纵向扩展

- __哨兵模式：__
  - 一主多从的模式+哨兵集群。哨兵提供故障转移，主备切换的工作。主节点做读写处理，从节点只做数据备份的工作。
  - 缺点
    - 单个主节点性能压力大；
    - 从节点不能处理请求，浪费资源

- __集群模式：__
  - 多主多从，无中心架构，一个主节点对应一个从节点。采用一致性HASH算法，来使数据均匀分布在主节点上。主节点提供读写操作，从节点只做数据备份和故障转移。
  - 优点：
    - 1、无中心架构
    - 2、数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布。
    - 3、可扩展性，可线性扩展到1000多个节点，节点可动态添加或删除。
    - 4、高可用性，部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升。
    - 5、降低运维成本，提高系统的扩展性和可用性。

  - 缺点：
    - 1、Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。
    - 2、节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种failover是没有必要的。
    - 3、数据通过异步复制,不保证数据的强一致性。
    - 4、多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。


### 1.6、缓存和DB双写一致性问题

- __概念描述：__
  - 数据库里的值和缓存中的数据不一致的现象就叫做数据库和缓存双写一致性问题
  - 在高并发的情况下很难去保证数据库和缓存的数据永远一致，我们只能去确保最终一致性。

- __plan1：给缓存设置失效时间__
    - 统一要求当缓存失效时再去数据库中查数据更新缓存

- __plan2：Cache Aside Pattern__
  - 写的时候先更新数据库，再删缓存的策略
  - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 
    标准的Pattern，facebook就是使用这种方式，具体流程如下：
    - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
    - 命中：应用程序从cache中取数据，取到后返回。
    - 更新：先把数据存到数据库中，成功后，再让缓存失效。
  - 问题：
    1. 缓存刚好失效
    2. 请求A查询数据库，得一个旧值
    3. 请求B将新值写入数据库
    4. 请求B删除缓存
    5. 请求A将查到的旧值写入缓存 ok，如果发生上述情况，确实是会发生脏数据

- __plan3：先删除缓存，再更新数据库策略__
  - 缺点：
    - 并发情况下，A删除了缓存，B进行查询，找到旧值写入缓存，A再更新DB，造成不一致问题

- __plan3升级：延迟双删__
  - 先删除缓存，再更新数据库，等待一定时间后再删除缓存
  - 缺点：
    - 

- __最佳方案：__
  - 给缓存设置失效时间，达成最终一致性
  - Cache Aside Pattern方案


### 1.7、延时队列

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

- __延时队列的应用场景__
  - 订单：比如电商业务，提交订单之后30分钟内未完成付款将取消订单
  - 通知：在任务完成后的一段时间给用户发送通知
  - 重试：业务操作失败后，间隔一段时间后进行失败重试

- __RabbitMQ的死信队列也可实现延时队列__

- __延时队列相对于定时扫描的优点__
  - 定时扫描数据量过大时会消耗太多的IO资源，效率太低
  - 定时扫描有一定的时间差





## 二、ElasticSearch




## 三、MongoDB





## 参考文章
#### 关系数据库  
- [开发人心里都该有的那颗 B 树](https://cloud.tencent.com/developer/article/1497410)  
- [为什么 MySQL 索引要使用 B+树而不是其它树形结构？比如 B 树？](https://juejin.im/post/5d519d576fb9a06b2116dce4)
- [mysql语句执行分析](https://cloud.tencent.com/developer/article/1498250)
- [五分钟搞清楚 MVCC 机制](https://cloud.tencent.com/developer/article/1497291)
- [五分钟搞清楚MySQL事务隔离级别](https://mp.weixin.qq.com/s?__biz=MzI1Mzg4OTMxNQ==&mid=2247484138&idx=1&sn=77f222160f8f26cbb868eb7a4547e7f1&chksm=e9ccdca6debb55b0e7e565aa2b69ca6b05e5f965f84a0317fa6c26191a229c00aa03f1757228&scene=21#wechat_redirect)
- [MySQL锁(表锁,行锁,共享锁,排它锁,间隙锁)使用详解](https://www.cnblogs.com/drizzle-xu/p/10435638.html)
- [mysql占用CPU超过100%解决过程](https://blog.csdn.net/jimshen/article/details/78706538)
- [mysql InnoDB引擎的行锁和表锁](https://blog.csdn.net/qq_23473123/article/details/80069708)
- [mysql锁——innodb的行级锁](https://www.cnblogs.com/huangfuyuan/p/9510022.html)
- [MySQL锁(表锁,行锁,共享锁,排它锁,间隙锁)使用详解](https://www.cnblogs.com/drizzle-xu/p/10435638.html)
- [100道MySQL数据库经典面试题解析（收藏版）](https://juejin.im/post/5ec15ab9f265da7bc60e1910#heading-6)
- [手把手教你分析Mysql死锁问题](https://juejin.im/post/5e8b269f518825739379e82c)
- [InnoDB MVCC 机制，看这篇就够了](https://www.codercto.com/a/88775.html)
- [我以为我对Mysql事务很熟，直到我遇到了阿里面试官](https://zhuanlan.zhihu.com/p/148035779)
- [MySQL 优化之 index_merge （索引合并）](http://blog.itpub.net/28939273/viewspace-2154349/)

#### nosql数据库
- [Redis与Mysql双写一致性方案解析](https://zhuanlan.zhihu.com/p/59167071)
- [Redis 数据结构和对象系统](https://juejin.im/post/5d067941f265da1bb13f30d2)
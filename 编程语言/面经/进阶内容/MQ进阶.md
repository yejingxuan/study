
# MQ进阶 

- [MQ进阶](#mq进阶)
  - [一、MQ简介](#一mq简介)
    - [1.1、MQ的优点](#11mq的优点)
    - [1.2、MQ的缺点](#12mq的缺点)
    - [1.3、常用MQ](#13常用mq)
  - [二、数据一致性问题](#二数据一致性问题)
    - [2.1、重复消费问题](#21重复消费问题)
    - [2.2、丢失数据问题](#22丢失数据问题)
  - [三、如何保证MQ顺序执行](#三如何保证mq顺序执行)
    - [3.1、rabbitMQ保证顺序消费](#31rabbitmq保证顺序消费)
    - [3.2、kafka保证顺序消费](#32kafka保证顺序消费)
  - [四、MQ高可用](#四mq高可用)
    - [4.1、rabbitMQ高可用](#41rabbitmq高可用)
    - [4.2、kafka的高可用](#42kafka的高可用)
  - [五、灾难恢复问题](#五灾难恢复问题)
  - [参考文章](#参考文章)


## 一、MQ简介

### 1.1、MQ的优点
- __解耦__
  - 看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......

- __异步__
  - 再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。

- __削峰__
  - 每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。

  - 一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

  - 但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

### 1.2、MQ的缺点
- __系统可用性降低__
  - 系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以点击这里查看。

- __系统复杂度提高__
  - 硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。

- __一致性问题__
  - A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。


### 1.3、常用MQ

- rabbitMQ

- kafka

- rocketMQ


## 二、数据一致性问题

### 2.1、重复消费问题
如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？

- __kafka重复消息场景__
  - Kafka 有个 offset 的概念，每个消息写进去，都有一个 offset，代表消息的序号，consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
  - 因此会存在，消息者处理消息后，突然宕机，此时还没来得及提交offset,重启之后，少数消息会再次消费一次。

- __kafka重复消费问题解决__
  - 其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。
  - 如果进行数据写库，先根据主键查一下，如果数据已存在，就放弃插入
  - 比如是写入Redis缓存，每次都是 set，天然幂等性。
  - 借助中间件，报错每次消费消息后，消息的唯一值，缺点：需要维护另一个中间件，还得考虑中间件挂掉的情况。


### 2.2、丢失数据问题

- __RabbitMQ丢数据的三种情况：__
  __1. 生产者弄丢了数据__
    - 生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了
    - __解决方案__
      - 此时可以选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit，__缺点是吞吐量会下来，因为太耗性能__
      - 要确保说写 RabbitMQ 的消息别丢，可以开启 confirm 模式，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

  __2. RabbitMQ弄丢消息__
    - 消息暂存在内存中，还未被消费，RabbitMQ挂掉了，内存中的数据丢失。
    - __解决方案__
      - 开启 RabbitMQ 的持久化，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小
      - 哪怕是给 RabbitMQ 开启了持久化机制，也有一种可能，就是消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失
      - 持久化可以跟生产者的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了

  __3. 消费者弄丢了数据__
    - 消费者刚收到消费，还没处理，结果进程挂，RabbitMQ的自动ack机制认为你消费了，导致数据丢了。
    - __解决方案__
      - 用 RabbitMQ 提供的 ack 机制，简单来说，就是必须关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。

    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200527153810.png)

- __Kafka丢数据的三种情况__
  __1. 生产者丢消息的情况__
    - Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产：
      ```
      0 —表示不进行消息接收是否成功的确认；
      1 —表示当Leader接收成功时确认；
      -1/all —表示Leader和Follower都接收成功时确认；
      ```

    - 综上所述，有2种消息丢失的场景：
      - （1）acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失；
      - （2）acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，数据可能丢失；

    - __解决方案__
      - 在 producer 端设置 acks=-1/all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。

  __2. Kafka丢消息的情况__
    - Kafka 某个分片的leader宕机，然后重新选举分片的 leader。此时其他的 follower 刚好还有些数据没有同步，然后选举某个 follower 成 leader 之后，就少了一些数据

    - __解决方案__
      - 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本
      - 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧
      - 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了
      - 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了

  __3. 消费者丢消息的情况__
    - 消费到了消息，消费者那边自动提交了 offset，让 Kafka 以为已经消费好了这个消息，消费者在处理业务逻辑的时候挂了，此时这条消息就丢了
    - __解决方案__
      - 关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。此时确实还是可能会有重复消费，需要自己保证幂等性




## 三、如何保证MQ顺序执行

### 3.1、rabbitMQ保证顺序消费

- __消费乱序场景一__
  - 一个队列被多个消费者消费，消费者内部处理时间不同，导致DB中的执行顺序不同。
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200527110004.png)

  - 场景一解决方案：
    - 有N个消费者就把quene进行拆分为N个队列，每个消费者消费一个队列，然后把需要保证顺序的一组消息放到同一个队列里。


- __消费乱序场景二__
  - 一个队列，一个消费者的情景下，消费者开启多线程进行消费，线程执行时间不同，导致DB中的执行顺序不同。

  - 场景二解决方案
    - 在消费者内部，若有N个线程，则创建N个内存队列，每个线程只操作自己的内存队列，把需要保证顺序的一组消息放到同一队列中。

### 3.2、kafka保证顺序消费

- __kafka特性__
  - __一个分片只能被同一消费组内的一个消费者消费，可以保证一个分片内的数据是被有序消费的，我们只需把需要一组顺序执行的消息，设置同样的key值，就可以把这组消息发送到同一个分片中。__
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200527141518.png)


- __消费乱序场景__
  - 消费者内部使用多线程处理的话，线程执行时间不同，导致DB中的执行顺序不同，解决方案同rabbitMQ场景二

## 四、MQ高可用

### 4.1、rabbitMQ高可用
RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

- __普通集群模式（无高可用性）__
  - 普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来

  - __缺点:__
    - 没做到所谓的分布式，每个机器只有部分数据。导致消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈
    - 而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据

  - __优点：__
    - 这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。

- __镜像集群模式（高可用性）__
  - 每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。每次写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上
  - __缺点：__
    - 性能开销太大了，消息需要同步到所有机器上，导致网络带宽压力和消耗很重
    - 不是分布式的，没有扩展性可言，如果某个 queue 负载很重，加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue
  - __优点：__
    - 任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据


### 4.2、kafka的高可用

kakfa是天然的分布式消息队列，kafka集群由多个 broker 组成，每个 broker 是一个节点；每创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据

- __kafka副本机制提供高可用方案__
  ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200527141904.png)

  - 每个分片的数据都会同步到其它机器上，形成自己的多个副本。所有副本会选举一个 leader 出来，生产和消费都跟这个 leader 交互，其他副本就是 follower。如果某个leader宕机了，那么此时会从 follower 中重新选举一个新的 leader 出来，续读写新的 leader 即可
  - 写数据的时候，生产者只写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者
  - 消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。
  - Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性


## 五、灾难恢复问题


## 参考文章
- [中华石衫-如何保证消息队列的高可用？](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md)
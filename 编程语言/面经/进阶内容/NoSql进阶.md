
# NoSql进阶

- [NoSql进阶](#nosql进阶)
  - [一、Redis](#一redis)
    - [1.1、Redis的基本数据结构和底层原理](#11redis的基本数据结构和底层原理)
    - [1.2、Redis持久化](#12redis持久化)
    - [1.3、集群同步机制](#13集群同步机制)
    - [1.2、Redis的IO模型](#12redis的io模型)
    - [1.3、Redis的多线程模型](#13redis的多线程模型)
    - [1.4、Redis集群的一致性算法](#14redis集群的一致性算法)
    - [1.5、Redis的高可用方案](#15redis的高可用方案)
    - [1.6、缓存和DB双写一致性问题](#16缓存和db双写一致性问题)
    - [1.7、延时队列](#17延时队列)
  - [二、ElasticSearch](#二elasticsearch)
  - [三、MongoDB](#三mongodb)
  - [四、参考文章](#四参考文章)


## 一、Redis

### 1.1、Redis的基本数据结构和底层原理


### 1.2、Redis持久化

- __RDB：__ 
  - RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化

- __AOF：__ 
  - AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的binlog

### 1.3、集群同步机制

- Redis的主从模式采用的是RDB文件同步的方式，因为Redis的服务端，数据量有可能非常的大，所以从性能考虑，没有采用AOF快照来同步。

- __全量过程大概如下：__
  1. 从机上线，主动链接主机，发送SYNC命令
  2. 主机接到命令后，执行BGSAVE命令，生成RDB文件
  3. 主机向从机发送RDB文件，开始同步数据
  4. 同步之后，主机将最近的更新，采用命令的形式同步到从机上面。

- __增量过程：__
  1. 当从机断线重连之后，会发送PSYNC,要求增量同步，并包括一个offset
  2. 主机根据offset的位置，对之后的数据进行一次增量同步，到从机上面（offset是由主机和从机共同维护的，相当于一个乐观锁，描述了两方的版本差异）

- __决定能否增量同步的主要因素：__
  1. 是否具备偏移量，与主机进行对比
  2. 主服务器的复制积压缓冲区（Replication backlog）
       - Redis每分钟都会处理很多的数据，不可能一直把更新的操作存起来，等待从机上线在传输，AOF也不是都在内存中一直保存，所以Redis有一个缓冲区，采用队列的模式来存储这些写操作。

       - 所有的更新操作以队列的形式放入里面，内存大小默认是1MB，超过1MB之后，前面进入队列的写操作就会被移除。

       - 所以当从机上线之后，如果offset与主机版本差距的内容还在缓冲区内，则可以从缓冲区进行增量同步。否则依然还是全量同步（RDB），这里就好比你的机器宕机了一天，在上线，你不能要求我把这一天的数据都给你吧，你直接全量同步得了。

       - 这里我就想到了一个问题，如果我们反复对Redis更新特别大的K-V的话，超过1M，会使得这个缓冲区失效，因为每次的更新都超过这个缓冲区大小了，所以同步操作对于从机来说，都是全量同步，如果太频繁的话，则会产生很大的问题。

       - 这个缓冲区的大小也是可以设置调整的饿，可以根据需求配置
  3. 从服务器的ID
     - Redis有一个Slot的概念，每个机器负责一部分的Key，所以如果你之前不是我的从机，那你内存内的数据肯定都不是我的值，就不能只看offset了，还要看一下你之前是不是我的从机，这里主机会维护从机的唯一ID，来校验。


### 1.2、Redis的IO模型


### 1.3、Redis的多线程模型

- __redis6.0之后加入了多线程模型__
- __初始化三类线程__
  - 这三类线程被认为是后台执行.不影响主线程

  1. BIO_CLOSE_FILE . 关闭重写之前的aof文件.
  2. BIO_AOF_FSYNC . 定时刷新数据到磁盘上.
  3. BIO_LAZY_FREE . 惰性删除过期时间数据


### 1.4、Redis集群的一致性算法


### 1.5、Redis的高可用方案

- __主从模式：__
  - 一主多从的结构部署，主节点提供读写操作，从节点提供读的操作，主节点数据自动同步至从节点。可以有效的解决读多写少的情景，把读请求均摊到从节点上。
  - 缺点：
    - 不能自动进行故障转移，主备切换，需要手动操作或者自己编写客户端脚本进行处理。
    - 主库的写能力和存储能力受到单机的限制，
    - 每个从库都保存的主库完整数据，无法纵向扩展

- __哨兵模式：__
  - 一主多从的模式+哨兵集群。哨兵提供故障转移，主备切换的工作。主节点做读写处理，从节点只做数据备份的工作。
  - 缺点
    - 单个主节点性能压力大；
    - 从节点不能处理请求，浪费资源

- __集群模式：__
  - 多主多从，无中心架构，一个主节点对应一个从节点。采用一致性HASH算法，来使数据均匀分布在主节点上。主节点提供读写操作，从节点只做数据备份和故障转移。
  - 优点：
    1、无中心架构
    2、数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布。
    3、可扩展性，可线性扩展到1000多个节点，节点可动态添加或删除。
    4、高可用性，部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升。
    5、降低运维成本，提高系统的扩展性和可用性。

  - 缺点：
    1、Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。
    2、节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种failover是没有必要的。
    3、数据通过异步复制,不保证数据的强一致性。
    4、多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。


### 1.6、缓存和DB双写一致性问题

- __概念描述：__
  - 数据库里的值和缓存中的数据不一致的现象就叫做数据库和缓存双写一致性问题
  - 在高并发的情况下很难去保证数据库和缓存的数据永远一致，我们只能去确保最终一致性。

- __plan1：给缓存设置失效时间__
    - 统一要求当缓存失效时再去数据库中查数据更新缓存

- __plan2：Cache Aside Pattern__
  - 写的时候先更新数据库，再删缓存的策略
  - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。 
    标准的Pattern，facebook就是使用这种方式，具体流程如下：
    - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
    - 命中：应用程序从cache中取数据，取到后返回。
    - 更新：先把数据存到数据库中，成功后，再让缓存失效。
  - 问题：
    1. 缓存刚好失效
    2. 请求A查询数据库，得一个旧值
    3. 请求B将新值写入数据库
    4. 请求B删除缓存
    5. 请求A将查到的旧值写入缓存 ok，如果发生上述情况，确实是会发生脏数据

- __plan3：先删除缓存，再更新数据库策略__
  - 缺点：
    - 
    - 

- __plan3升级：延迟双删__
  - 先删除缓存，再更新数据库，等待一定时间后再删除缓存
  - 缺点：
    - 

- __最佳方案：__
  - 给缓存设置失效时间，达成最终一致性
  - Cache Aside Pattern方案


### 1.7、延时队列

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

- __延时队列的应用场景__
  - 订单：比如电商业务，提交订单之后30分钟内未完成付款将取消订单
  - 通知：在任务完成后的一段时间给用户发送通知
  - 重试：业务操作失败后，间隔一段时间后进行失败重试

- __RabbitMQ的死信队列也可实现延时队列__

- __延时队列相对于定时扫描的优点__
  - 定时扫描数据量过大时会消耗太多的IO资源，效率太低
  - 定时扫描有一定的时间差





## 二、ElasticSearch




## 三、MongoDB




## 四、参考文章
- [Redis与Mysql双写一致性方案解析](https://zhuanlan.zhihu.com/p/59167071)
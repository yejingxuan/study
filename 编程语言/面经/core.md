- [一、JAVA基础](#%e4%b8%80java%e5%9f%ba%e7%a1%80)
  - [1.1、集合详解](#11%e9%9b%86%e5%90%88%e8%af%a6%e8%a7%a3)
  - [1.2、多线程](#12%e5%a4%9a%e7%ba%bf%e7%a8%8b)
  - [1.3、线程池](#13%e7%ba%bf%e7%a8%8b%e6%b1%a0)
  - [1.4、NIO && IO多路复用模型](#14nio--io%e5%a4%9a%e8%b7%af%e5%a4%8d%e7%94%a8%e6%a8%a1%e5%9e%8b)
  - [1.5、java中的锁](#15java%e4%b8%ad%e7%9a%84%e9%94%81)
  - [1.6、延时队列](#16%e5%bb%b6%e6%97%b6%e9%98%9f%e5%88%97)
- [二、JVM](#%e4%ba%8cjvm)
  - [2.1、JVM结构](#21jvm%e7%bb%93%e6%9e%84)
  - [2.2、类加载机制](#22%e7%b1%bb%e5%8a%a0%e8%bd%bd%e6%9c%ba%e5%88%b6)
  - [2.3、垃圾回收算法](#23%e5%9e%83%e5%9c%be%e5%9b%9e%e6%94%b6%e7%ae%97%e6%b3%95)
  - [2.4、垃圾标记算法](#24%e5%9e%83%e5%9c%be%e6%a0%87%e8%ae%b0%e7%ae%97%e6%b3%95)
  - [2.5、JVM调优](#25jvm%e8%b0%83%e4%bc%98)
- [三、DB](#%e4%b8%89db)
  - [3.1、mysql的存储引擎](#31mysql%e7%9a%84%e5%ad%98%e5%82%a8%e5%bc%95%e6%93%8e)
  - [3.2、三范式](#32%e4%b8%89%e8%8c%83%e5%bc%8f)
  - [3.3、索引](#33%e7%b4%a2%e5%bc%95)
  - [3.3、事务](#33%e4%ba%8b%e5%8a%a1)
  - [3.4、SQL优化](#34sql%e4%bc%98%e5%8c%96)
  - [3.5、数据库锁](#35%e6%95%b0%e6%8d%ae%e5%ba%93%e9%94%81)
  - [3.7、分库分表](#37%e5%88%86%e5%ba%93%e5%88%86%e8%a1%a8)
  - [3.8、MVCC机制](#38mvcc%e6%9c%ba%e5%88%b6)
- [四、Kafka](#%e5%9b%9bkafka)
  - [4.1、两种消息模型](#41%e4%b8%a4%e7%a7%8d%e6%b6%88%e6%81%af%e6%a8%a1%e5%9e%8b)
  - [4.2、kafka结构原理](#42kafka%e7%bb%93%e6%9e%84%e5%8e%9f%e7%90%86)
  - [4.3、kafka消费策略](#43kafka%e6%b6%88%e8%b4%b9%e7%ad%96%e7%95%a5)
  - [4.4、kafka扩容，重新分区](#44kafka%e6%89%a9%e5%ae%b9%e9%87%8d%e6%96%b0%e5%88%86%e5%8c%ba)
  - [4.5、性能优化](#45%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96)
- [五、RabbitMQ](#%e4%ba%94rabbitmq)
  - [5.1、结构原理](#51%e7%bb%93%e6%9e%84%e5%8e%9f%e7%90%86)
  - [5.2、消息调度策略](#52%e6%b6%88%e6%81%af%e8%b0%83%e5%ba%a6%e7%ad%96%e7%95%a5)
  - [5.3、消息确认机制（Message Acknowledgment）](#53%e6%b6%88%e6%81%af%e7%a1%ae%e8%ae%a4%e6%9c%ba%e5%88%b6message-acknowledgment)
  - [5.4、消息分发机制](#54%e6%b6%88%e6%81%af%e5%88%86%e5%8f%91%e6%9c%ba%e5%88%b6)
  - [5.5、持久化 & 死信队列 & 延时队列](#55%e6%8c%81%e4%b9%85%e5%8c%96--%e6%ad%bb%e4%bf%a1%e9%98%9f%e5%88%97--%e5%bb%b6%e6%97%b6%e9%98%9f%e5%88%97)
- [六、Redis](#%e5%85%adredis)
  - [6.1、Reids数据类型](#61reids%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b)
  - [6.2、缓存雪崩 & 缓存穿透 & 缓存击穿](#62%e7%bc%93%e5%ad%98%e9%9b%aa%e5%b4%a9--%e7%bc%93%e5%ad%98%e7%a9%bf%e9%80%8f--%e7%bc%93%e5%ad%98%e5%87%bb%e7%a9%bf)
  - [6.3、双写一致性问题](#63%e5%8f%8c%e5%86%99%e4%b8%80%e8%87%b4%e6%80%a7%e9%97%ae%e9%a2%98)
  - [6.4、分布式锁](#64%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81)
  - [6.5、延时队列](#65%e5%bb%b6%e6%97%b6%e9%98%9f%e5%88%97)
  - [6.6、Redis持久化](#66redis%e6%8c%81%e4%b9%85%e5%8c%96)
  - [6.7、集群同步机制](#67%e9%9b%86%e7%be%a4%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6)
  - [6.8、redis slot 槽点](#68redis-slot-%e6%a7%bd%e7%82%b9)
  - [6.8、HA集群高可用](#68ha%e9%9b%86%e7%be%a4%e9%ab%98%e5%8f%af%e7%94%a8)
  - [6.9、数据淘汰策略（6种）](#69%e6%95%b0%e6%8d%ae%e6%b7%98%e6%b1%b0%e7%ad%96%e7%95%a56%e7%a7%8d)
  - [6.10、Redis为什么快](#610redis%e4%b8%ba%e4%bb%80%e4%b9%88%e5%bf%ab)
  - [6.11、Redis与Memcached区别](#611redis%e4%b8%8ememcached%e5%8c%ba%e5%88%ab)
- [七、ZooKeeper](#%e4%b8%83zookeeper)
  - [7.1、结构原理](#71%e7%bb%93%e6%9e%84%e5%8e%9f%e7%90%86)
  - [7.2、选主投票机制](#72%e9%80%89%e4%b8%bb%e6%8a%95%e7%a5%a8%e6%9c%ba%e5%88%b6)
  - [7.3、应用场景](#73%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af)
  - [7.4、](#74)
  - [7.5、](#75)
- [八、分布式](#%e5%85%ab%e5%88%86%e5%b8%83%e5%bc%8f)
  - [8.1、springcloud](#81springcloud)
  - [8.2、负载均衡](#82%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1)
  - [8.1、限流](#81%e9%99%90%e6%b5%81)
  - [8.2、熔断](#82%e7%86%94%e6%96%ad)
  - [8.3、服务降级](#83%e6%9c%8d%e5%8a%a1%e9%99%8d%e7%ba%a7)
  - [8.4、高可用](#84%e9%ab%98%e5%8f%af%e7%94%a8)
  - [8.5、一致性HASH算法](#85%e4%b8%80%e8%87%b4%e6%80%a7hash%e7%ae%97%e6%b3%95)
  - [8.6、分布式文件存储](#86%e5%88%86%e5%b8%83%e5%bc%8f%e6%96%87%e4%bb%b6%e5%ad%98%e5%82%a8)
- [九、ElasticSearch](#%e4%b9%9delasticsearch)
  - [9.1、ES分布式架构原理](#91es%e5%88%86%e5%b8%83%e5%bc%8f%e6%9e%b6%e6%9e%84%e5%8e%9f%e7%90%86)
  - [9.2、如何合理设计分片和副本](#92%e5%a6%82%e4%bd%95%e5%90%88%e7%90%86%e8%ae%be%e8%ae%a1%e5%88%86%e7%89%87%e5%92%8c%e5%89%af%e6%9c%ac)
  - [9.3、ES数据流程](#93es%e6%95%b0%e6%8d%ae%e6%b5%81%e7%a8%8b)
  - [9.4、检索](#94%e6%a3%80%e7%b4%a2)
  - [9.5、score计算](#95score%e8%ae%a1%e7%ae%97)
  - [9.6、ES的性能优化](#96es%e7%9a%84%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96)
  - [9.7、生产部署](#97%e7%94%9f%e4%ba%a7%e9%83%a8%e7%bd%b2)
  - [9.7、倒排索引](#97%e5%80%92%e6%8e%92%e7%b4%a2%e5%bc%95)
- [十、开发框架](#%e5%8d%81%e5%bc%80%e5%8f%91%e6%a1%86%e6%9e%b6)
  - [10.1、spring](#101spring)
  - [10.2、mybatis](#102mybatis)
- [十一、Design Pattern](#%e5%8d%81%e4%b8%80design-pattern)
- [十二、Dev Utils](#%e5%8d%81%e4%ba%8cdev-utils)
  - [11.1、Git](#111git)

## 一、JAVA基础

### 1.1、集合详解 

### 1.2、多线程

 - __线程状态__
    - __new__ 新建状态，线程对象已经创建，但尚未启动

    - __runnable__ 就绪状态，可运行状态，调用了线程的start方法，已经在java虚拟机中执行，等待获取操作系统资源如CPU，操作系统调度运行。 这个状态下发生的等待一般是其他系统资源, 而不是锁, Sleep等


    - __blocked__  阻塞状态下, 是在多个线程有同步操作的场景, 比如正在等待另一个线程的synchronized 块的执行释放, 或者可重入的 synchronized块里别人调用wait() 方法, 也就是这里是线程在等待进入临界区
    
    - __waiting__  等待状态下是指线程拥有了某个锁之后, 调用了他的wait方法, 等待其他线程/锁拥有者调用 notify / notifyAll 一遍该线程可以继续下一步操作, 这里要区分 BLOCKED 和 WATING 的区别, 一个是在临界点外面等待进入, 一个是在理解点里面wait等待别人notify, 线程调用了join方法 join了另外的线程的时候, 也会进入WAITING状态, 等待被他join的线程执行结束
    
    - __timed_waiting__  这个状态就是有限的(时间限制)的WAITING, 一般出现在调用wait(long), join(long)等情况下, 另外一个线程sleep后, 也会进入TIMED_WAITING状态
    
    - __terminated__ 这个状态下表示 该线程的run方法已经执行完毕了, 基本上就等于死亡了(当时如果线程被持久持有, 可能不会被回收)


​      
      ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200509171056.png)

  - __wait和sleep的区别__
    - 对于sleep()方法，我们首先要知道该方法是属于Thread类中的。而wait()方法，则是属于Object类中的。
    - sleep()方法的过程中，线程进入TIMED_WAITING时间，并不会释放锁，在设定时间到或被interrupt后抛出InterruptedException后进入RUNNABLE状态。而当调用wait()方法的时候，线程会放弃对象锁，进入waiting状态，只有针对此对象调用notify()方法后本线程才进入blocked状态，拿到锁内进入runnable状态
    - wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
    - sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常。

  - __start和run的区别__
    - 线程的任务处理逻辑可以在Tread类的run实例方法中直接实现或通过该方法进行调用，因此run()相当于线程的任务处理逻辑的入口方法，它由Java虚拟机在运行相应线程时直接调用，而不是由应用代码进行调用。
    - 而start()的作用是启动相应的线程。启动一个线程实际是请求Java虚拟机运行相应的线程，而这个线程何时能够运行是由线程调度器决定的。start()调用结束并不表示相应线程已经开始运行，这个线程可能稍后运行，也可能永远也不会运行。


### 1.3、线程池

  - __线程池的优点__
    - 第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    - 第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
    - 第三：提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用线程池，必须对其实现原理了如指掌

  - __ThreadPoolExecutor构造方法详解：__
    |参数名 |作用|
    |:--:|:--:|
    |corePoolSize   |核心线程池大小|
    |maximumPoolSize|最大线程池大小|
    |keepAliveTime  |线程池中超过corePoolSize数目的空闲线程最大存活时间|
    |TimeUnit       |keepAliveTime时间单位|
    |workQueue      |阻塞任务队列|

  - __构造函数__
    - __newSingleExecutor__
      ```java
      public static ExecutorService newSingleThreadExecutor() {
          return new FinalizableDelegatedExecutorService
              (new ThreadPoolExecutor(1, 1,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>()));
      }
      ```
      - 因为LinkedBlockingQueue是长度为Integer.MAX_VALUE的队列，可以认为是无界队列，因此往队列中可以插入无限多的任务，在资源有限的时候容易引起OOM异常，同时因为无界队列，maximumPoolSize和keepAliveTime参数将无效，压根就不会创建非核心线程

    - __newFixedThreadPool__
      ```java
      public static ExecutorService newFixedThreadPool(int nThreads) {
          return new ThreadPoolExecutor(nThreads, nThreads,
                                        0L, TimeUnit.MILLISECONDS,
                                        new LinkedBlockingQueue<Runnable>());
      }

      ```
      - 允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而引起OOM异常


    - __newCachedThreadPool__
      ```java
      public static ExecutorService newCachedThreadPool() {
          return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                        60L, TimeUnit.SECONDS,
                                        new SynchronousQueue<Runnable>());
      }
      ```
      - 当一个任务提交时，corePoolSize为0不创建核心线程，SynchronousQueue是一个不存储元素的队列，可以理解为队里永远是满的，因此最终会创建非核心线程来执行任务。
    
      - 对于非核心线程空闲60s时将被回收。因为Integer.MAX_VALUE非常大，可以认为是可以无限创建线程的，在资源有限的情况下容易引起OOM异常
    
    - __总结__
      - FixedThreadPool和SingleThreadExecutor => 允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而引起OOM异常
    
      - CachedThreadPool => 允许创建的线程数为Integer.MAX_VALUE，可能会创建大量的线程，从而引起OOM异常

  - __工作流程__

    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/线程池.jpg)

    1. 判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。

    2. 线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。

    3. 判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。

  - __RejectedExecutionHandler：饱和策略__
    - 1、AbortPolicy（默认策略）：直接抛出异常
    - 2、CallerRunsPolicy：调用所在的主线程运行任务
    - 3、DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
    - 4、DiscardPolicy：不处理，丢弃掉。



  - __threadlocal原理__
    - 每个线程Thread对象都包含一个成员变亮，threadlocalMap，threadlocald的put，get方法实际操作的是线程独有的threadlocalMap变量
    - threadLocalMap将当前线程对象t作为key，要存储的对象作为value存到map里面去。如果该Map不存在，则初始化一个。
    - threadlocal的内存泄露问题：
      ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200522181031.png)
      - 通过源码知道threadLocalMap是threadlocal的一个静态内部类，主要用entry存储数据，而entry还是弱引用
        ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200522181629.png)
      - 为什么entry是弱引用呢，主要为了解决内存泄露问题。假如entry是强引用，当threadlocal的值在运行结束后被设置为null，但是threadlocalmap中还保存这threadlocal的强引用，导致threadlocal无法被回收。产生内存泄露，而当是虚引用的时候，则完全可以回收掉threadlocal。
      - 但是当threadlocal作为map的key被回收后，value却无法被回收，所以我们最好用完threadlocal后手动remove掉key.




### 1.4、NIO && IO多路复用模型
  > [Java NIO：IO与NIO的区别 -阿里](https://www.cnblogs.com/aspirant/p/8630283.html)
  > [NIO面试题](https://blog.csdn.net/qq_14842117/article/details/90722837)
  > https://www.cnblogs.com/1994jinnan/p/12203355.html

  NIO可以称之为 new IO,也可以称之为NoBlocking IO(非阻塞IO)

  - __IO多路复用模型__
    - I/O multiplexing 这里面的 multiplexing 指的其实是在单个线程通过记录跟踪每一个Sock(I/O流)的状态(对应空管塔里面的Fight progress strip槽)来同时管理多个I/O流. 发明它的原因，是尽量多的提高服务器的吞吐能力。

    - select, poll, epoll 都是I/O多路复用的具体的实现，之所以有这三个鬼存在，其实是他们出现是有先后顺序的。

  - __select__
    - I/O多路复用这个概念被提出来以后， select是第一个实现 (1983 左右在BSD里面实现的)
    - select 会修改传入的参数数组，这个对于一个需要调用很多次的函数，是非常不友好的。 
    - select 如果任何一个sock(I/O stream)出现了数据，select 仅仅会返回，但是并不会告诉你是那个sock上有数据，于是你只能自己一个一个的找，10几个sock可能还好，要是几万的sock每次都找一遍，这个无谓的开销就颇有海天盛筵的豪气了。
    - select 只能监视1024个链接， 这个跟草榴没啥关系哦，linux 定义在头文件中的，参见FD_SETSIZE。
    - select 不是线程安全的，如果你把一个sock加入到select, 然后突然另外一个线程发现，尼玛，这个sock不用，要收回。对不起，这个select 不支持的，如果你丧心病狂的竟然关掉这个sock, select的标准行为是。。呃。。不可预测的， 这个可是写在文档中的哦.

  - __poll__
    - poll 去掉了1024个链接的限制，于是要多少链接呢， 主人你开心就好。
    - poll 从设计上来说，不再修改传入数组，不过这个要看你的平台了，所以行走江湖，还是小心为妙。

  - __epoll__
    - epoll 现在是线程安全的。 
    - epoll 现在不仅告诉你sock组里面数据，还会告诉你具体哪个sock有数据，你不用自己去找
    - epoll 有个致命的缺点。。只有linux支持


### 1.5、java中的锁

  - __乐观锁__
    - 乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作
    - CAS:CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。
  
  - __悲观锁__
    - 悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁。java中的悲观锁就是 Synchronized,
    - AQS  (AbstractQueuedSynchronizer 抽象队列同步器)  AQS框架下的锁则是先尝试 cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock

  - __自旋锁__
    - 自旋锁原理非常简单， 如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。


  - __synchronize同步锁__
    - synchronize是java中的一个关键字，它可以对方法、代码块进行加锁操作
      - 同步普通方法，锁的是当前对象。
      - 同步静态方法，锁的是当前 Class 对象。
      - 同步代码块，锁的是 {} 中的对象。
    - synchronized的原理
      - JVM 是通过进入、退出对象监视器( Monitor )来实现对方法、同步块的同步的。

      - 具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。

      - 其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。

      - 而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。

  - __ReentrantLock 可重入锁__
    
- ReentantLock 继承接口 Lock 并实现了接口中定义的方法， 他是一种可重入锁， 除了能完成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。
    
  - __synchronized 和 ReentrantLock 的区别__
    - 共同点
      1. 都是用来协调多线程对共享对象、变量的访问
      2. 都是可重入锁，同一线程可以多次获得同一个锁
      3. 都保证了可见性和互斥性
    - 不同点
      1. ReentrantLock 显示的获得、释放锁， synchronized 隐式获得释放锁
      2. ReentrantLock 可响应中断、可轮回， synchronized 是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性
      3. ReentrantLock 是 API 级别的， synchronized 是 JVM 级别的
      4. ReentrantLock 可以实现公平锁
      5. ReentrantLock 通过 Condition 可以绑定多个条件
      6. 底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略， lock 是同步非阻塞，采用的是乐观并发策略
      7. Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现。
      8. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁。
      9. Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断。
      10. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
      11. Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。

  - __AQS__
    - aqs全称为AbstractQueuedSynchronizer，它提供了一个FIFO队列，可以看成是一个用来实现同步锁以及其他涉及到同步功能的核心组件，常见的有:ReentrantLock、CountDownLatch等
    - 从使用层面来说，AQS的功能分为两种：独占和共享
      - 独占锁，每次只能有一个线程持有锁，比如前面给大家演示的ReentrantLock就是以独占方式实现的互斥锁
      - 共享锁，允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock

  - __volatile关键字__
    > https://www.sohu.com/a/211287207_684445
  
    一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

    1. 保证线程之间变量可见性：保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
    2. 禁止指令重排序：禁止进行指令重排序。

    在访问 volatile 变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此 volatile 变量是一种比 sychronized 关键字更轻量级的同步机制。 volatile 适合这种场景：一个变量被多个线程共享，线程直接给这个变量赋值。

  - __指令重排__
    - 指令重排是指JVM在编译Java代码的时候，或者CPU在执行JVM字节码的时候，对现有的指令顺序进行重新排序。
    - 指令重排的目的是为了在不改变程序执行结果的前提下，优化程序的运行效率。需要注意的是，这里所说的不改变执行结果，指的是不改变单线程下的程序执行结果。
    - 指令重排是一把双刃剑，虽然优化了程序的执行效率，但是在某些情况下，会影响到多线程的执行结果。我们来看看下面的例子
    - 内存屏障（Memory Barrier）是一种CPU指令，它使CPU或编译器对屏障指令之前和之后发出的内存操作执行一个排序约束。 这通常意味着在屏障之前发布的操作被保证在屏障之后发布的操作之前执行。

  - DCL(double check lock)


### 1.6、延时队列



## 二、JVM

### 2.1、JVM结构
![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200506153958.png)

  - __按内存区域来划分：__
    - __线程私有数据区域__ 生命周期与线程相同，依赖用户线程的启动/结束而创建/销毁
    - __线程共享区域__ 随虚拟机的启动/关闭而创建/销毁
    - __直接内存__ 并不是 JVM 运行时数据区的一部分, 但也会被频繁的使用: 在 JDK 1.4 引入的 NIO 提供了基于 Channel 与 Buffer 的 IO 方式, 它可以使用 Native 函数库直接分配堆外内存, 然后使用DirectByteBuffer 对象作为这块内存的引用进行操作(详见: Java I/O 扩展), 这样就避免了在 Java堆和 Native 堆中来回复制数据, 因此在一些场景中可以显著提高性能。

  - __详细介绍：__
    - 虚拟机栈
      - Java 虚拟机栈是基于线程的。哪怕你只有一个 main() 方法，也是以线程的方式运行的。在线程的生命周期中，参与计算的数据会频繁地入栈和出栈，栈的生命周期是和线程一样的。
      - 每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
    
    - 本地方法栈
      - 本地方法区和 Java Stack 作用类似, 区别是虚拟机栈为执行 Java 方法服务, 而本地方法栈则为Native 方法服务, 如果一个 VM 实现使用 C-linkage 模型来支持 Native 调用, 那么该栈将会是一个C 栈，但 HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一。

    - 程序计数器
      - 一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有” 的内存
      - 正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址） 。如果还是 Native 方法，则为空
      - 这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域

    - 堆
      - 是被线程共享的一块内存区域， 创建的对象和数组都保存在 Java 堆内存中，也是垃圾收集器进行垃圾收集的最重要的内存区域。 由于现代 VM 采用分代收集算法, 因此 Java 堆从 GC 的角度还可以细分为: 新生代(Eden 区、 From Survivor 区和 To Survivor 区)和老年代。

    - 方法区
      - 即我们常说的永久代(Permanent Generation), 用于存储被 JVM 加载的类信息、 常量、 静态变量、 即时编译器编译后的代码等数据。
  
  - __JVM运行时内存：__
    Java 堆从 GC 的角度还可以细分为: 
    - 新生代(位于堆中、细分为Eden 区、 From Survivor 区和 To Survivor 区)
      - 是用来存放新生的对象。一般占据堆的 1/3空间。由于频繁创建对象，所以新生代会频繁触发MinorGC 进行垃圾回收。
    - 老年代（位于堆中）
      - 主要存放应用程序中生命周期长的内存对象。老年代的对象比较稳定，所以 MajorGC 不会频繁执行。
    - 永久代（位于方法区）
      - 指内存的永久保存区域，主要存放 Class 和 Meta（元数据）的信息,Class 在被加载的时候被放入永久区域， 它和和存放实例的区域不同,GC 不会在主程序运行期对永久区域进行清理。所以这也导致了永久代的区域会随着加载的 Class 的增多而胀满，最终抛出 OOM 异常
      - 在 Java8 中， 永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间的本质和永久代类似，元空间与永久代之间最大的区别在于： 元空间并不在虚拟机中，而是使用本地内存
      - 元空间的好处也是它的坏处。使用非堆可以使用操作系统的内存，JVM 不会再出现方法区的内存溢出；但是，无限制的使用会造成操作系统的死亡。所以，一般也会使用参数-XX:MaxMetaspaceSize 来控制大小

### 2.2、类加载机制
  - __类加载过程：__
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200506161017.png)
    - 加载：
      - 将外部的 .class 文件，加载到 Java 的方法区内。加载阶段主要是找到并加载类的二进制数据，比如从 jar 包里或者 war 包里找到它们。
    - 验证：
      - 确保 Class 文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。不符合规范的将抛出 java.lang.VerifyError 错误。
    - 准备
      - 为一些类变量分配内存，并将其初始化为默认值。此时，实例对象还没有分配内存，所以这些动作是在方法区上进行的
    - 解析：
      - 将符号引用替换为直接引用。符号引用是一种定义，可以是任何字面上的含义，而直接引用就是直接指向目标的指针、相对偏移量。解析阶段负责把整个类激活，串成一个可以找到彼此的网
    - 初始化
      - 初始化成员变量，到了这一步，才真正开始执行一些字节码。

  - __双亲委派机制：__
    - 当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class）， 子类加载器才会尝试自己去加载。
    - __优点：__ __虚拟机只有在两个类的类名相同且加载该类的加载器均相同的情况下才判定这是一个类__。若不采用双亲委派机制，同一个类有可能被多个类加载器加载，这样该类会被识别为两个不同的类，相互赋值时会有问题。双亲委派机制能保证多加载器加载某个类时，最终都是由一个加载器加载，确保最终加载结果相同。



### 2.3、垃圾回收算法

  - __标记清除算法（Mark-Sweep）：__
    - 最基础的垃圾回收算法，分为两个阶段，标注和清除。标记阶段标记出所有需要回收的对象，清除阶段回收被标记的对象所占用的空间
    - 该算法最大的问题是内存碎片化严重，后续可能发生大对象不能找到可利用空间的问题

  - __复制算法（copying）：__
    - 按内存容量将内存划分为等大小的两块。每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用的内存清掉
    - 算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原本的一半。且存活对象增多的话， Copying 算法的效率会大大降低

  - __标记整理算法（Mark-Compact）__
    - 标记阶段和 Mark-Sweep 算法相同， 标记后不是清理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。
    - 避免了内存碎片化和被压缩为一半的问题，缺点是效率要比前两种低

  - __分代收集算法__
    - 分代收集法是目前大部分 JVM 所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生代(YoungGeneration)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法
    - 目前大部分 JVM 的 GC 对于新生代都采取 Copying 算法，因为新生代中每次垃圾回收都要回收大部分对象，即要复制的操作比较少，但通常并不是按照 1： 1 来划分新生代。一般将新生代划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space)，每次使用Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另一块 Survivor 空间中。
    - 而老年代因为每次只回收少量对象，因而采用 Mark-Compact 算法

  - __CMS垃圾收集器__
    - 基于标记清除算法的CMS收集器 [深入理解JVM之——CMS垃圾收集器的工作原理解析](https://blog.csdn.net/qq_28203555/article/details/105384981?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)

  - __G1垃圾收集器__
    - Garbage first 垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与 CMS 收集器， G1 收集器两个最突出的改进是：
      1. 基于标记-整理算法，不产生内存碎片。
      2. 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。

    - G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间， 优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。

### 2.4、垃圾标记算法

  - __引用计数法 Reference Counting__
    - 给对象添加一个引用计数器，每过一个引用计数器值就+1，少一个引用就-1。当它的引用变为0时，该对象就不能再被使用。它的实现简单，但是不能解决互相循环引用的问题。

  - __根搜索算法 GC ROOT Tracing__
    - GC Roots基本思路就是通过一系列的称为“GC Roots”的对象作为起始点， 从这些节点开始向下搜索， 搜索所走过的路径称为引用链（ Reference Chain），当一个对象到 GC Roots 没有任何引用链相连（ 用图论的话来 说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。

    - 常说的GC(Garbage Collector) Roots，特指的是垃圾收集器（Garbage Collector）的对象，GC会收集那些不是GC Roots且没有被GC Roots引用的对象。

    - 一个对象可以属于多个root，GC Roots有以下几种：

      - Class - 由系统类加载器(system class loader)加载的对象，这些类是不能够被回收的，他们可以以静态字段的方式保存持有其它对象。我们需要注意的一点就是，通过用户自定义的类加载器加载的类，除非相应的Java.lang.Class实例以其它的某种（或多种）方式成为roots，否则它们并不是roots，.
      - Thread - 活着的线程
      - Stack Local - Java方法的local变量或参数
      - JNI Local - JNI方法的local变量或参数
      - JNI Global - 全局JNI引用
      - Monitor Used - 用于同步的监控对象
      - Held by JVM - 用于JVM特殊目的由GC保留的对象，但实际上这个与JVM的实现是有关的。可能已知的一些类型是：系统类加载器、一些JVM知道的重要的异常类、一些用于处理异常的预分配对象以及一些自定义的类加载器等。然而，JVM并没有为这些对象提供其它的信息，因此需要去确定哪些是属于"JVM持有"的了。

### 2.5、JVM调优
  - __JVM参数__
    - -开头的参数表示标准参数，所以jvm都支持
    - -X开头的表示非标准参数
    -  -XX开头的参数
       -  java -XX:+PrintCommandLineFlags -version
       -  UseCompressedClassPointers  压缩类指针
       -  UseCompressedOops  压缩对象

  - __如何避免频繁full GC__
    - 问题剖析
      - Full GC本身是好的，可以清除老年代的垃圾，但是如果Full GC发生的频率高了，就会影响性能，同时意味着系统内存分配机制出现问题。
      - 因为Full GC本身执行时间较长（甚至超过1秒），而且除非采用G1 GC，否则其它的GC方式都会或多或少挂起所有线程执行（Stop-the-world），如果Full GC频繁发生，系统被挂起的次数就会增加，响应时间就会变慢。
      - Full GC频繁发生，意味着你的内存分配机制存在问题，也许是内存泄露，有大量内存垃圾不断在老年代产生；也许是你的大对象（缓存）过多；也有可能是你的参数设置不好，minor GC清理不掉内存，导致每次minor GC都会触发Full GC；还有可能是你的老年代大小参数设置错误，老年代过小等等原因
    - 解决方案
      - 排查是否内存泄露，或者大对象例如缓存过多
      - 排查是否老年代内存设置过小
      - 排查minor GC参数，是否minor GC清理不掉内存导致


## 三、DB

### 3.1、mysql的存储引擎

  - __InnoDB：__
    - InnoDB 底层存储结构为B+树， B树的每个节点对应innodb的一个page， page大小是固定的，
      一般设为 16k。其中非叶子节点只有键值，叶子节点包含完成数据

    - 适用场景：
      1）经常更新的表，适合处理多重并发的更新请求。
      2）支持事务。
      3）可以从灾难中恢复（通过 bin-log 日志等）。
      4）外键约束。只有他支持外键。
      5）支持自动增加列属性 auto_increment。
  
  - __MyIsam：__
    - MyIASM是 MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，
      因此当 INSERT(插入)或 UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。

    - ISAM 执行读取操作的速度很快，而且不占用大量的内存和存储资源。在设计之初就预想数据组织
      成有固定长度的记录，按顺序存储的。 ---ISAM 是一种静态索引结构。

  - __Memory：__
    - Memory（也叫 HEAP）堆内存：使用存在内存中的内容来创建表。每个 MEMORY 表只实际对应一个磁盘文件。 MEMORY 类型的表访问非常得快，因为它的数据是放在内存中的，并且默认使用HASH 索引。但是一旦服务关闭，表中的数据就会丢失掉。 Memory 同时支持散列索引和 B 树索引， B树索引可以使用部分查询和通配查询，也可以使用<,>和>=等操作符方便数据挖掘，散列索引相等的比较快但是对于范围的比较慢很多


  - __InnoDB和MyIsam的区别__
    > [MyISAM与InnoDB 的区别（9个不同点）](https://blog.csdn.net/qq_35642036/article/details/82820178)
    - InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务
    - InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败
    - InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的，MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。__详情可参考3.3聚簇索引和非聚簇索引__
    - InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁

### 3.2、三范式

  - __第一范式：__
    - 表的列的具有原子性,不可再分解，即列的信息，不能分解，通俗理解即一个字段只存储一项信息。

  - __第二范式：__
    - 首先满足第一范式，并且数据库表中的每个实例或行必须可以被惟一地区分。为实现区分通常需要我们设计一个主键来实现(这里的主键不包含业务逻辑)。
    
    - 即满足第一范式前提，当存在多个主键的时候，才会发生不符合第二范式的情况。比如有两个主键，不能存在这样的属性，它只依赖于其中一个主键，这就是不符合第二范式。通俗理解是任意一个字段都只依赖表中的同一个字段。（涉及到表的拆分）
  
  - __第三范式：__
    - 第三范式定义是，满足第二范式，并且表中不包含已在其它表中已包含的非主键字段
    - 表的信息，如果能够被推导出来，就不应该单独的设计一个字段来存放(能尽量外键join就用外键join)。很多时候，我们为了满足第三范式往往会把一张表分成多张表。

### 3.3、索引

  - __索引的种类__
    - 普通索引
    - 唯一索引
    - 主键索引
    - 组合索引
    - 全文索引

  - __索引方法__
    - B-Tree，
    - Hash，
    - R-Tree,
    - bitmap
    - REVERSE
    - 函数索引

  - __聚簇索引__
    - 通俗说法：将数据存储与索引放到了一块，找到索引也就找到了数据
    - InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分；

  - __非聚簇索引__
    - 将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行

### 3.3、事务
事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作， 这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行 。 事务是一个不可分割的工作逻辑单元事务必须具备以下四个属性，简称 ACID 属性：
  - __事务特性：__

    - A（Atomicity）原子性
      - 事务是一个完整的操作。事务的各步操作是不可分的（原子的）；要么都执行，要么都不执行

    - C（Consistency）一致性
      - 当事务完成时，数据必须处于一致状态

    - I（Isolation）隔离性
      - 对数据进行修改的所有并发事务是彼此隔离的， 这表明事务必须是独立的，它不应以任何方式依赖于或影响其他事务

    - D（Durability）持久性
      - 事务完成后，它对数据库的修改被永久保持，事务日志能够保持事务的永久性

  - __事务隔离级别：__
    ANSI/ISO SQL标准定义了4中事务隔离级别：
    - __未提交读（read uncommitted）：__ Read Uncommitted是隔离级别最低的一种事务级别。在这种隔离级别下，已发生脏读（Dirty Read）
    - __提交读（read committed）：__ 在Read Committed隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题
    - __重复读（repeatable read）：__ 在Repeatable Read隔离级别下，一个事务可能会遇到幻读（Phantom Read）的问题。
    - __串行读（serializable）：__ Serializable是最严格的隔离级别。在Serializable隔离级别下，所有事务按照次序依次执行，因此，脏读、不可重复读、幻读都不会出现。虽然Serializable隔离级别下的事务具有最高的安全性，但是，由于事务是串行执行，所以效率会大大下降，应用程序的性能会急剧降低。如果没有特别重要的情景，一般都不会使用Serializable隔离级别。
    - 不同的隔离级别有不同的现象，并有不同的锁定/并发机制，隔离级别越高，数据库的并发性就越差，4种事务隔离级别分别表现的现象如下表：

      |隔离级别         |脏读|不可重复读|幻读|
      |----------------|----|-------|------|
      |read uncommitted|允许|允许    |允许  |
      |read committed  |    |允许    |允许  |
      |repeatable read |    |        |允许 |
      |serializable    |    |        |     |

 - __事务隔离导致的问题__

    - __脏读（dirty read）__
      - Read Uncommitted是隔离级别最低的一种事务级别。在这种隔离级别下，一个事务会读到另一个事务更新后但未提交的数据，如果另一个事务回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read）。
      - 简单来说就是读到别的事务没有提交的数据。


    - __不可重复读（nonrepeatable read）__
      - 在Read Committed隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题。不可重复读是指，两个相同的查询返回了不同的结果，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。
      - 简单来说先前读取的数据，被别的事务改变了，再读就跟原来不一样了。
    
    - __幻读（phantom read）__
      - MySql默认的隔离级别为Repeatable Read（重复读），因此只会出现幻读的情况。幻读是指，在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功（或者插入该记录出现主键冲突），并且，再次读取同一条记录，它就神奇地出现了。
      - 简单来说就是第一次读的时候发现什么都没有，另一个事务偷偷放了东西进去，再去访问的时候惊讶地居然发现有东西了
    
    - __幻读和不可重复读的区别：__
      - 幻读中事务二的数据操作仅仅是插入和删除，读取的记录数量前后不一致。而不可重复读中是修改数据，导致同一个查询返回了不同的结果

### 3.4、SQL优化

### 3.5、数据库锁

  - __行级锁：__
    - 行级锁是一种排他锁，防止其他事务修改此行；在使用以下语句时， Oracle 会自动应用行级锁：
      1. INSERT、 UPDATE、 DELETE、 SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];
      2. SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新
      3. 使用 COMMIT 或 ROLLBACK 语句释放锁
    - MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
    - 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
    - 由于mysql 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但如果是使用相同的索引键，是会出现锁冲突的
      - a. 使用相同索引键值的冲突
      - b. 使用不同索引键值但是同一行的冲突
      - c. 创建了索引，但使用的是表锁
      > [mysql InnoDB引擎的行锁和表锁](https://blog.csdn.net/qq_23473123/article/details/80069708)  、  [mysql锁——innodb的行级锁](https://www.cnblogs.com/huangfuyuan/p/9510022.html)
  
  - __InnoDB三种行锁__
      - Record Lock（行锁）：单个行记录上的范围
        - Record Lock总是会锁住索引记录，如果InnoDB存储引擎建立的时候没有设置任何一个索引，这时InnoDB存储引擎会使用隐式的主键来进行锁定。
        - 行锁锁定的是索引记录，而不是行数据，也就是说锁定的是key。
      - Gap Lock（间隙锁）：锁定一个范围，但不包含记录本身
        - Gap Lock在InnoDB的唯一作用就是防止其他事务的插入操作，以此防止幻读的发生。
      - Next-Key Lock（后码锁）：锁定一个范围，并且锁定记录本身 Gap Lock + Record Lock

  - __表级锁：__
    
- 表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分 MySQL 引擎支持。最常使用的 MYISAM 与 INNODB 都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）
    
  - __页级锁：__
    
- 页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 BDB 支持页级锁
    
  - __死锁：__
    - MyISAM表锁是deadlock free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，当两个事务都需要获得对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。
    - 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200426113818.png)
    
    - 事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。
    
    - 当出现死锁以后，有两种策略：
      1. 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
      2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。减少死锁的主要方向，就是控制访问相同资源的并发事务量。



### 3.7、分库分表

  - __垂直切分：__
    - 将表按照功能模块、关系密切程度划分出来， 部署到不同的库上。例如，我们会建立定义数据库 workDB、商品数据库 payDB、用户数据库 userDB、日志数据库 logDB 等，分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200424180152.png)

  - __水平切分：__
    - 按照规则划分存储，当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，例如 userID 散列，进行划分，然后存储到多个结构相同的表，和不同的库上
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200424180117.png)

  - __mycat分库分表插件__


### 3.8、MVCC机制

> [InnoDB MVCC 机制，看这篇就够了](https://www.codercto.com/a/88775.html)

MVCC (Multiversion Concurrency Control)  中文全称叫 多版本并发控制 ，是现代数据库（包括MySQL 、 Oracle 、 PostgreSQL  等）引擎实现中常用的处理读写冲突的手段， 目的在于提高数据库高并发场景下的吞吐性能。

如此一来不同的事务在并发过程中， SELECT  操作可以不加锁而是通过  MVCC  机制读取指定的版本历史记录，并通过一些手段保证保证读取的记录值符合事务所处的隔离级别，从而解决并发场景下的读写冲突。

- __InnoDB MVCC实现原理__
InnoDB  中  MVCC  的实现方式为：每一行记录都有两个隐藏列： DATA_TRX_ID 、 DATA_ROLL_PTR （如果没有主键，则还会多一个隐藏的主键列）。
  - DATA_TRX_ID：记录最近更新这条行记录的 事务 ID ，大小为  6  个字节
  - DATA_ROLL_PTR：表示指向该行回滚段 （rollback segment） 的指针，大小为  7  个字节， InnoDB  便是通过这个指针找到之前版本的数据。该行记录上所有旧版本，在  undo  中都通过链表的形式组织。
  - DB_ROW_ID：行标识（隐藏单调自增  ID ），大小为  6  字节，如果表没有主键， InnoDB  会自动生成一个隐藏主键，因此会出现这个列。另外，每条记录的头信息（ record header ）里都有一个专门的  bit （ deleted_flag ）来表示当前记录是否已经被删除。



## 四、Kafka

### 4.1、两种消息模型

  - __点对点：__


  - __发布订阅：__

### 4.2、kafka结构原理

Kafka 是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由 LinkedIn 公司开发，使用
Scala 语言编写，目前是 Apache 的开源项目。
  - __基础概念：__
    - broker： Kafka 服务器，负责消息存储和转发
    - topic：消息类别， Kafka 按照 topic 来分类消息
    - partition： topic 的分区，一个 topic 可以包含多个 partition， topic 消息保存在各个partition 上
    - offset：消息在日志中的位置，可以理解是消息在 partition 上的偏移量，也是代表该消息的唯一序号
    - Producer：消息生产者
    - Consumer：消息消费者
    - Consumer Group：消费者分组，每个 Consumer 必须属于一个 group
    - Zookeeper：保存着集群 broker、 topic、 partition 等 meta 数据；另外，还负责 broker 故障发现， partition leader 选举，负载均衡等功能

  - __存储原理：__
    - 在Kafka文件存储中，同一个topic下有多个不同partition，每一个partition为一个文件夹，partiton命名规则为topic名称+有序序号，第一个partiton序号从0開始，序号最大值为partitions数量减1。
    - 每一个partion(文件夹)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件里。segment file组成：由2大部分组成。分别为index file和data file，此2个文件一一相应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件。
    - 在partition中怎样通过offset查找message，比如读取offset=368776的message，须要通过以下2个步骤查找。
      - 第一步查找segment file 当中00000000000000000000.index表示最開始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.相同，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1。其它兴许文件依次类推。以起始偏移量命名并排序这些文件，仅仅要依据offset 二分查找文件列表，就能够高速定位到具体文件。 
    当offset=368776时定位到00000000000000368769.index|log

      - 第二步通过segment file查找message 通过第一步定位到segment file，当offset=368776时。依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。

  - __Kafka高效文件存储设计特点：__

    - Kafka把topic中一个parition大文件分成多个小文件段。通过多个小文件段，就easy定期清除或删除已经消费完文件。降低磁盘占用。

    - 通过索引信息能够高速定位message和确定response的最大大小。

    - 通过index元数据所有映射到memory，能够避免segment file的IO磁盘操作。

    - 通过索引文件稀疏存储，能够大幅降低index文件元数据占用空间大小。

### 4.3、kafka消费策略

### 4.4、kafka扩容，重新分区

### 4.5、性能优化
  - __批量发送__
      - 是提高消息吞吐量重要的方式， Producer 端可以在内存中合并多条消息后， 以一次请求的方式发送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响了消息的实时性，相当于以时延代价，换取更好的吞吐量。
  - __压缩（GZIP 或 Snappy）__
      - Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后，在Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是 CPU（压缩和解压会耗掉部分 CPU 资源）。


## 五、RabbitMQ

### 5.1、结构原理
  - __架构图__
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200429113107.png)

    一般来说，我们提到消息队列的时候，生产者是与消息队列直接联系的，但 RabbitMQ 在此之上，多做了一层抽象，在生产者与消息队列之前插入了一个交换器（Exchange），从而实现了生产者与消息队列的解耦。

  - __基础概念__
    - Producer 生产者：向消息队列发布消息的客户端应用程序。

    - Channel 信道：多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的 TCP 连接内的虚拟连接，复用 TCP 连接的通道。

    - Exchange 交换器：提供 Producer 到 Queue 之间的匹配，接收生产者发送的消息并将这些消息按照路由规则转发到消息队列。交换器用于转发消息，它不会存储消息 ，若没有 Queue 绑定到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息。

    - Binding 绑定：Binding 用于建立 Exchange 和 Queue 之间的关联。

    - Queue 消息队列：保存消息，直到消息发送给消费者。注意一个消息可投入一个或多个队列。

    - Consumer 消费者：从消息队列取得消息的客户端应用程序。

    - Broker 服务器：RabbitMQ 服务器


### 5.2、消息调度策略

  - __消息调度策略__ 
    指的是在收到生产者发送的消息后，Exchange 根据什么规则将消息转发到队列中。

    RabbitMQ 为我们提供了四种 Exchange，分别是 fanout，direct，topic，header，而 header 模式在实际使用中较少

    - Routing Key：路由键，用于标记消息的路由规则，决定了交换机的转发路径。
    - Binding Key：绑定键，用于匹配 Routing Key，表示 Exchange 与 Queue 的绑定关系。

  - __Fanout__
    Fanout 又被称为订阅/广播模式。该模式模式与 Binding Key 和 Routing Key 无关，Exchange 将接收到的消息分发给所有与该交换器绑定的消息队列。注意，Fanout 转发消息是最快的。

  - __Direct__
    Direct 即是路由模式，也是 Exchange 的默认模式。唯有当 Routing Key 与 Binding Key 完全匹配的时候才将消息发送至消息队列。

    事实上，RabbitMQ 默认提供了一个 Exchange，名字是空字符串，类型是 Direct，绑定到所有的Queue 上（每一个 Queue 和这个无名 Exchange 之间的 Binding Key 是 Queue 的名字）。所以，有时候我们感觉不需要 Exchange 也可以发送和接收消息，实际上是使用了 RabbitMQ 默认提供的 Exchange。

  - __Topic__
    Topic 就是通配符模式。Routing Key 与 Binding Key 会根据正则表达式进行模糊匹配，若匹配成功则会将消息转发至消息队列。

### 5.3、消息确认机制（Message Acknowledgment）
  - 我们现在假设一种情况，消费者刚刚收到消息队列发来的信息，却不幸宕机，导致了信息丢失，这该咋办呢？

  - 其实，这种情况完全可以通过消费者在消费完消息后发送一个回执给 RabbitMQ 解决，这也被称为消息确认机制。RabbitMQ 在收到消费回执之后才将消息移除出消息队列，若没有收到信息回执并检测到消费者的 RabbitMQ 连接断开，那么 RabbitMQ 会将该消息发送给其他消费者进行处理。

  - 需要注意的是，只要消费者的 RabbitMQ 连接没有断开，无论消费者处理消息时间有多长，都不会导致该消息被发送给其他消费者。


### 5.4、消息分发机制

  - __轮询分发__
    - 轮询分发，Round-robin dispatching，也是 RabbitMQ 的默认消息分发机制。队列会给每一个消费者发送的数据数量是一模一样的，并不会因为两个消费者处理数据速度不同而发生改变。这样很容易导致部分消费者天天加班，而部分消费者无所事事的情况。

    - 轮询分发是 RabbitMQ 默认的消息分发机制。

  - __公平分发__
    - 公平分发，Fair dispatch，消费者设置每次从队列里只取一条数据，并且关闭自动回复机制，每次取完一条数据后，手动回复并继续取下一条数据。这样每个消费者都只有消费完一条消息才会收到下一条消息，十分的“公平”。（每个消费者在同一时间点最多处理的消息个数由 prefetchCount 参数规定，而不是固定为1个）

    - 需要注意的是，如果我们使用公平分发，那么必须关闭自动应答，同时改为手动应答。


### 5.5、持久化 & 死信队列 & 延时队列

  - __持久化：__
    - 死信队列，又称 dead-letter-exchange（DLX）。当一条消息在一个队列中变成死信后，它会被重新发布到一个交换机中，这个交换机就是 DLX。

  - __死信队列：__
    - 消息被拒绝（reject ，nack），并且 requeue = false（不再重新投递）
    - 消息 TTL 过期
    - 队列超过最长长度

  - __延时队列：__
    - 我们在网上购物，提交订单之后30分钟内必须付款，否则就会取消订单，这种情况下，我们不可能单单只开启一个异步线程而不做其他处理。在这里，我可以提供一种方案来解决这个问题，那就是使用延时消息队列。在消息发布之后，保存在消息中间件中，延时一段时间之后才会发布至队列中。延时队列监听器在这段时间结束后才能监听到消息并开始执行

    - RabbitMQ 本身并没有直接实现延时队列，但是我们可以使用 RabbitMQ 的属性（TTL，DLX）来模拟一个延时队列。我们可以在消息上设置过期时间，然后在消息队列上为死信指定转发器，这样消息过期后会转发到与指定转发器匹配的死信队列上，从而实现延时队列。







## 六、Redis

### 6.1、Reids数据类型
  - __String：__
    - 这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。
    - 许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。例如秒杀场景
    - 共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie，但是可以利用Redis将用户的Session集中管理，在这种模式只需要保证Redis的高可用，每次用户Session的更新和获取都可以快速完成。大大提高效率
  
  - __Hash：__
    - 类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段
    - 做数据字典使用
    - Redis 中的 Hash和 Java的 HashMap 比较相似,都是数组+链表的结构.当发生 hash 碰撞时将会把元素追加到链表上.值得注意的是在 Redis 的 Hash 中 value 只能是字符串。在 Java 中 HashMap 扩容是个很耗时的操作,需要去申请新的数组,为了追求高性能,Redis 采用了渐进式 rehash 策略.这也是 hash 中最重要的部分。
      ```
      a. Redis是在插入新节点之前判断是否需要进行扩容，如果不需要，则直接插入，否则需要先扩容，再插入新节点。
      b. 在扩容的时候 rehash 策略会保留新旧两个 hashtable 结构,查询时也会同时查询两个 hashtable.Redis会将旧 hashtable 中的内容一点一点的迁移到新的 hashtable 中,当迁移完成时,就会用新的 hashtable 取代之前的.当 hashtable 移除了最后一个元素之后,这个数据结构将会被删除
      c. 服务器目前没有在执行BGSAVE命令或者BGREWRITEAPF命令，并且 哈希表保存的key的数量 / 哈希表的大小>=1；
         服务器目前正在执行BGSAVE命令或者BGREWRITEAPF命令，并且 哈希表保存的key的数量 / 哈希表的大小>=5;
      d. 因为在rehash的过程中，字典会同时使用两个哈希表，所以在rehash期间，字典的删除、查找、更新、增加等操作会在两个哈希表中进行
      e. 渐进式rehash避免了redis阻塞（原来进行一次put操作，要等到rehash全部结束，这个操作才会返回，现在则只需要辅助rehash一步），但是由于在rehash时，需要分配一个新的hash表，在rehash期间，同时有两个hash表在使用，会使得redis内存使用量瞬间突增，在Redis 满容状态下由于Rehash会导致大量Key驱逐
      ```



  - __List：__
    - List 是有序列表，可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。
    - 可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走
    - 可以搞个简单的消息队列，从 List 头怼进去，从 List 屁股那里弄出来
  
  - __Set：__
    - Set 是无序集合，会自动去重
  
  - __SortSet：__
    - 是排序的 Set，去重但可以排序，每个元素都会关联一个double类型的分数。通过分数来为集合中的成员进行从小到大的排序
    - 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。
    - 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。
    - 可用来做延时队列
  
  - __HyperLogLog：__
    - Redis 在 2.8.9 版本添加了 HyperLogLog 结构。用来做基数统计,在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。
    - 每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数
    - 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

  - __Geo：__
    - GEO功能在Redis3.2版本提供，支持存储地理位置信息，用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能.geo的数据类型为zset
  
  - __Pub/Sub：__
    - 发布订阅模式，做简单的消息中间件，缺点是消息无法持久化，消费者掉线中，此时生产者有新消息产生后会丢失。
    - 订阅发布可以支持多客户端获取同一个频道发布的消息，当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的所有客户端。
  
  - __BloomFilter：__
    - 布隆过滤器，解决缓存穿透问题
  
  - __RedisSearch：__
    - 全文检索功能服务

### 6.2、缓存雪崩 & 缓存穿透 & 缓存击穿

  - __缓存雪崩：__

    - 目前电商首页以及热点数据都会去做缓存 ，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题  

    - a. 处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效，我相信，Redis这点流量还是顶得住的。setRedis（Key，value，time + Math.random() * 10000）；

    - b. 或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险  

  - __缓存穿透：__
    
    - 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库  

    - 在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return
    
    - 布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。


  - __缓存击穿：__

    - 至于缓存击穿嘛，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞

    - 设置热点数据永远不过期。或者加上互斥锁就能搞定了。


### 6.3、双写一致性问题

  - __概念描述：__
    数据库里的值和缓存中的数据不一致的现象就叫做  数据库和缓存双写一致性问题
      - 在高并发的情况下很难去保证数据库和缓存的数据永远一致，我们只能去确保最终一致性。

  - __常用解决方案：__
    - a. 给缓存设置失效时间
      - 统一要求当缓存失效时再去数据库中查数据更新缓存
    - b. 先更新数据库，再删缓存的策略（Cache Aside Pattern）
      标准的Pattern，facebook就是使用这种方式，具体流程如下：
      - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
      - 命中：应用程序从cache中取数据，取到后返回。
      - 更新：先把数据存到数据库中，成功后，再让缓存失效。
    - c. 先删除缓存，再更新数据库策略

  - __最佳方案：__
    - 给缓存设置失效时间，达成最终一致性
    - Cache Aside Pattern方案



### 6.4、分布式锁

### 6.5、延时队列

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

- __延时队列的应用场景__
  - 订单：比如电商业务，提交订单之后30分钟内未完成付款将取消订单
  - 通知：在任务完成后的一段时间给用户发送通知
  - 重试：业务操作失败后，间隔一段时间后进行失败重试

- __RabbitMQ的死信队列也可实现延时队列__

- __延时队列相对于定时扫描的优点__
  - 定时扫描数据量过大时会消耗太多的IO资源，效率太低
  - 定时扫描有一定的时间差

### 6.6、Redis持久化

- __RDB：__ RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化

- __AOF：__ AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的binlog

### 6.7、集群同步机制

  - Redis的主从模式采用的是RDB文件同步的方式，因为Redis的服务端，数据量有可能非常的大，所以从性能考虑，没有采用AOF快照来同步。

  - __全量过程大概如下：__
    1. 从机上线，主动链接主机，发送SYNC命令
    2. 主机接到命令后，执行BGSAVE命令，生成RDB文件
    3. 主机向从机发送RDB文件，开始同步数据
    4. 同步之后，主机将最近的更新，采用命令的形式同步到从机上面。

  - __增量过程：__
    1. 当从机断线重连之后，会发送PSYNC,要求增量同步，并包括一个offset
    2. 主机根据offset的位置，对之后的数据进行一次增量同步，到从机上面（offset是由主机和从机共同维护的，相当于一个乐观锁，描述了两方的版本差异）

  - __决定能否增量同步的主要因素：__
    1. 是否具备偏移量，与主机进行对比
    2. 主服务器的复制积压缓冲区（Replication backlog）
         - Redis每分钟都会处理很多的数据，不可能一直把更新的操作存起来，等待从机上线在传输，AOF也不是都在内存中一直保存，所以Redis有一个缓冲区，采用队列的模式来存储这些写操作。

         - 所有的更新操作以队列的形式放入里面，内存大小默认是1MB，超过1MB之后，前面进入队列的写操作就会被移除。

         - 所以当从机上线之后，如果offset与主机版本差距的内容还在缓冲区内，则可以从缓冲区进行增量同步。否则依然还是全量同步（RDB），这里就好比你的机器宕机了一天，在上线，你不能要求我把这一天的数据都给你吧，你直接全量同步得了。

         - 这里我就想到了一个问题，如果我们反复对Redis更新特别大的K-V的话，超过1M，会使得这个缓冲区失效，因为每次的更新都超过这个缓冲区大小了，所以同步操作对于从机来说，都是全量同步，如果太频繁的话，则会产生很大的问题。

         - 这个缓冲区的大小也是可以设置调整的饿，可以根据需求配置
    3. 从服务器的ID
       - Redis有一个Slot的概念，每个机器负责一部分的Key，所以如果你之前不是我的从机，那你内存内的数据肯定都不是我的值，就不能只看offset了，还要看一下你之前是不是我的从机，这里主机会维护从机的唯一ID，来校验。


### 6.8、redis slot 槽点

__Redis 集群没有使用一致性hash, 而是引入了哈希槽的概念。__
Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。

> https://www.jianshu.com/p/4163916a2a8a

- Hash槽和一致性Hash的区别
  - 一致性hash是一个0-2^32的闭合圆，Hash槽是一个2^14（16384）个槽组成的一个个槽区，
  - 一致性Hash存在hash倾斜的问题，而Hash槽是均匀分配的，
  - Hash槽key的定位规则是根据CRC-16(key)%16384的值来判断属于哪个槽区，从而判断该key属于哪个节点，而一致性哈希是根据hash(key)的值来顺时针找第一个hash(ip)的节点，从而确定key存储在哪个节点。
  - 一致性哈希是创建虚拟节点来实现节点宕机后的数据转移并保证数据的安全性和集群的可用性的。redis cluster是采用master节点有多个slave节点机制来保证数据的完整性的,master节点写入数据，slave节点同步数据。当master节点挂机后，slave节点会通过选举机制选举出一个节点变成master节点，实现高可用



### 6.8、HA集群高可用
  - __主从模式：__
    - 一主多从的结构部署，主节点提供读写操作，从节点提供读的操作，主节点数据自动同步至从节点。可以有效的解决读多写少的情景，把读请求均摊到从节点上。
    - 缺点：
      - 不能自动进行故障转移，主备切换，需要手动操作或者自己编写客户端脚本进行处理。
      - 主库的写能力和存储能力受到单机的限制，

  - __哨兵模式：__
    - 一主多从的模式+哨兵集群。哨兵提供故障转移，主备切换的工作。主节点做读写处理，从节点只做数据备份的工作。
    - 缺点
      - 单个主节点性能压力大；
      - 从节点不能处理请求，浪费资源

  - __集群模式：__
    - 多主多从，无中心架构，一个主节点对应一个从节点。采用一致性HASH算法，来使数据均匀分布在主节点上。主节点提供读写操作，从节点只做数据备份和故障转移。
    - 优点：
      1、无中心架构
      2、数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布。
      3、可扩展性，可线性扩展到1000多个节点，节点可动态添加或删除。
      4、高可用性，部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升。
      5、降低运维成本，提高系统的扩展性和可用性。

    - 缺点：
      1、Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。
      2、节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种failover是没有必要的。
      3、数据通过异步复制,不保证数据的强一致性。
      4、多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。


### 6.9、数据淘汰策略（6种）
Redis可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。
  - __volatile-lru：__
    - 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
  - __volatile-ttl：__
    - 从已设置过期时间的数据集中挑选将要过期的数据淘汰
  - __volatile-random：__
    - 从已设置过期时间的数据集中任意选择数据淘汰
  - __allkeys-lru：__
    - 从所有数据集中挑选最近最少使用的数据淘汰
  - __allkeys-random：__
    - 从所有数据集中任意选择数据进行淘汰
  - __noeviction：__
    - 禁止驱逐数据

### 6.10、Redis为什么快

  - 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
  - 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
  - 使用多路I/O复用模型，非阻塞IO；当有多个连接加入，但没有消息写入的时候，线程不会去主动管这些IO连接， 当有一个或多个连接有 I/O 事件时，会通知线程，线程就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作


### 6.11、Redis与Memcached区别


|     |redis  |Memcached|
|-----|------|--------|
| 数据类型| Redis 支持五种不同的数据类型，可以更灵活地解决问题|仅支持字符串类型|
|数据持久化|Redis 支持两种持久化策略：RDB 快照和 AOF 日志| Memcached 不支持持久化|
|分布式|Redis Cluster 实现了分布式的支持|Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。|
|内存管理机制|在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。|Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。|




## 七、ZooKeeper

### 7.1、结构原理

  - __存储结构图__
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200429162023.png)
    - /master：存储主节点的信息，若在主从模式中其没有数据，代表分布式应用的主节点还没有被选举出来。
    - /workers：下面的每个子 znode 代表一个从节点。
    - /tasks：下面的每个子 znode 代表一个任务，znode 上存储的信息代表着任务内容。
    - /assign：下面每个子 znode 代表一个从节点的任务集合。/assign/worker-1 代表从节点 worker-1 的任务集合，其下面的子 znode 都是分配给 worker-1 的任务。

  - __ZK角色__
    - leader：领导者。leader 作为整个 ZooKeeper 集群的主节点，负责响应所有对 ZooKeeper
    状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个集群内部消息处理的FIFO 。eader 为客户端提供读和写服务。

    - follower：追随者。follower 除了需要响应本服务器上的读请求外，还要处理 leader 的提议，并在 leader 提交提议时在本地也进行提交。需要注意的是，leader 和 follower 共同构成了 ZooKeeper 集群的法定人数，也就是说，只有他们才参与新 leader 的选举、响应 leader 的提议。

    - observer：观察者。若 ZooKeeper 集群的读取负载很高，可以设置一些 observer 服务器，以提高读取的吞吐量。observer 和 follower 比较相似，但还是具有两个区别：一是 observer 不属于法定人数，即不参加选举也不响应提议；二是 observer 不需要将事务持久化到磁盘，一旦 observer 被重启，需要从 leader 重新同步整个名字空间。需要注意，一个 ZooKeeper 集群同一时刻只会有一个 Leader，其他都是 Follower 或 Observer。


### 7.2、选主投票机制

- __ZAB协议：__
  
- Zab 协议有两种模式：Zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态
  
- __选主流程：__

  目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
  1. 服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反
  馈信息，服务器 1 的状态一直属于 Looking。
  2. 服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号
  大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是
  LOOKING。
  3. 服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编
  号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器
  1,2 成为小弟。
  4. 服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的
  编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。
  5. 服务器 5 启动，后面的逻辑同服务器 4 成为小弟


### 7.3、应用场景
- __分布式协调__
- __分布式锁__
- __元数据/配置信息管理__
- __HA高可用性__


### 7.4、


### 7.5、



## 八、分布式

### 8.1、springcloud
> [springCloud五大核心组件介绍](https://blog.csdn.net/CoreyXuu/article/details/87865274)

- __Eurkea__


- __Zuul__


- __Config__


- __Hystrix（断路器）__
  - 在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应
  - 熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误， 会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费 CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作
  - 路器很好理解, 当 Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况,如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN)


- __Ribbon__


- __Feigin__


- __Sleuth（链路追踪）__
  - 随着微服务数量不断增长，需要跟踪一个请求从一个微服务到下一个微服务的传播过程， SpringCloud Sleuth 正是解决这个问题，它在日志中引入唯一 ID，以保证微服务调用之间的一致性，这样你就能跟踪某个请求是如何从一个微服务传递到下一个
  - 为了实现请求跟踪，当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的跟踪标识，同时在分布式系统内部流转的时候，框架始终保持传递该唯一标识，直到返回给请求方为止， 这个唯一标识就是前文中提到的 Trace ID。通过 Trace ID 的记录，我们就能将所有请求过程日志关联起来

### 8.2、负载均衡

- __随机__
  - 随机就是没有规律的，随便从负载中获得一台，又分为完全随机和加权随机：

- __轮询__
  - 每一次来自网络的请求轮流分配给内部中的服务器，从 1 至 N 然后重新开始。此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况
  - 轮询又分为三种，1.完全轮询 2.加权轮询 3.平滑加权轮询


- __哈希__
  - 负载均衡算法中的哈希算法，就是根据某个值生成一个哈希值，然后对应到某台服务器上去，当然可以根据用户，也可以根据请求参数，或者根据其他，想怎么来就怎么来。如果根据用户，就比较巧妙的解决了负载均衡下Session共享的问题，用户小明走的永远是A服务器，用户小笨永远走的是B服务器。
  - 其实就是一致性Hash算法


- __最小压力__
  - 所以的最小压力负载均衡算法就是 选择一台当前最“悠闲”的服务器，如果A服务器有100个请求，B服务器有5个请求，而C服务器只有3个请求，那么毫无疑问会选择C服务器，这种负载均衡算法是比较科学的。

- __权重__


### 8.1、限流


### 8.2、熔断


### 8.3、服务降级


### 8.4、高可用


### 8.5、一致性HASH算法
> [一致性哈希算法详解](https://blog.csdn.net/Geffin/article/details/103092423)
  - 一致性哈希算法的倾斜问题：
    - 在服务节点太少时，节点分布容易不均匀，从而导致数据倾斜，即数据大部分存储在某一台服务器，如下图所示，大部分数据存储到了A节点上：
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200506140525.png)
    - 若服务器数量足够多，数据自然会均匀分布到每台服务器上去没有真正的物理服务器节点，我们还可以增加虚拟的服务器节点。对每一个服务节点计算多个哈希，然后在每个计算结果位置放置一个虚拟节点，具体做法可以通过在服务器 IP 地址或主机名后面增加编号来实现。
    - 例如添加C1虚拟节点，对A节点的数据进行重新HASH计算，分配部分数据到C1上，把虚拟节点C1的数据归并到C节点上。
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200506140836.png)

  - 一致性HASH算法应用场景：
    - 分布式缓存
    - 分布式存储
    - 分库分表水平拆分

### 8.6、分布式文件存储
  - Haystack 
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200511161240.png)
    - 架构比较简单，分为三部份：Haystack Directory, Haystack Cache, Haystack Store
    - Cache: 所谓的内部 CDN
    - Store: 最终落地存储服务

## 九、ElasticSearch

### 9.1、ES分布式架构原理
> https://blog.csdn.net/my201110lc/article/details/82017516



- __基本概念__

  - __集群(cluster)：__ 由一个或多个节点组成, 并通过集群名称与其他集群进行区分
    - es集群多个节点会自动选举出一个master节点，master节点一般干一些管理工作，比如维护索引的元数据，负责切换分片和副本的身份之类。如果master挂掉后，会重新选举出一个节点为master

  - __节点(node)：__ 单个ElasticSearch实例. 通常一个节点运行在一个隔离的容器或虚拟机中

  - __索引(index)：__ 在ES中, 索引是一组文档的集合,相当于mysql中的一张表
    - index-type-mapping-document-field
    - type：正常来说一个index里最好放一个type。比如说，有一个index，是订单index,
    - mapping：代表type的一个表结构定义
    - field：代表一个字段 

  - __分片(shard)：__ 因为ES是个分布式的搜索引擎, 所以索引通常都会分解成不同部分, 而这些分布在不同节点的数据就是分片. ES自动管理和组织分片, 并在必要的时候对分片数据进行再平衡分配, 所以用户基本上不用担心分片的处理细节，一个分片默认最大文档数量是20亿.
    - 每个分片最好不超过30GB的原则依然使用
    - 每创建一个索引index,会创建相关的shard,index的数据被分散的分布在每个shard里

  - __副本(replica)：__ ES默认为一个索引创建5个主分片, 并分别为其创建一个副本分片. 也就是说每个索引都由5个主分片组成, 而每个主分片都相应的有一个副本copy

- __分片和副本的区别__
  - 对于分布式搜索引擎来说, 分片及副本的分配将是高可用及快速搜索响应的设计核心.主分片与副本都能处理查询请求, 它们的唯一区别在于只有主分片才能处理索引请求.


### 9.2、如何合理设计分片和副本

- 一个好的方案是根据你的节点数量按照1.5~3倍的原则来创建分片. 例如,如果你有3个节点, 则推荐你创建的分片数最多不超过9(3x3)个.

- 随着数据量的增加,如果你通过集群状态API发现了问题,或者遭遇了性能退化,则只需要增加额外的节点即可. ES会自动帮你完成分片在不同节点上的分布平衡.

### 9.3、ES数据流程

- __ES写入数据流程__
  1. 客户端选择一个node发送请求过去，这个node作为协调节点（coordinating node）
  2. 协调节点对document进行hash计算，把请求路由到对应的node（即分片所在的node）,该node处理完写入请求后，再把请求路由到该分片副本所在node.
  3. 协调节点监听到分片和副本都写入成功后，返回给客户端成功信息

  - __ES数据写入分片的细节__
    1. 先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件
    2. 每隔 1 秒钟，es 将 buffer 中的数据写入一个新的 segment file，每秒钟会产生一个新的磁盘文件 segment file，这个 segment file 中就存储最近 1 秒内 buffer 中写入的数据。如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 refresh 到一个新的 segment file 中，但是此时数据不是直接进入 segment file 磁盘文件，而是先进入 os cache 。这个过程就是 refresh。
    3. 

  - __总结__
    - ES是准实时的，数据写入1s后才被refresh到os-cache中，然后可以搜索到（但是也可以手动执行refresh操作）；
    - ES也是可能会丢数据的，有5s的数据停留在buffer, translog, os-cache, segment-file中，如果宕机的话，会导致5s数据的丢失（如果一定不希望丢数据，可以设置参数，每天写入数据的时候，都是写入buffer,同时写入磁盘的translog，但是会导致写性能、写入吞吐量下降一个级别）

- __ES删除数据流程__


- __ES读取数据流程__
可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。
  1. 客户端发送请求到任意一个 node，成为 协调节点（coordinate node）。
  2. 协调节点 对 doc id 进行哈希路由，将请求转发到对应分片或者副本所在的 node（此时会使用 round-robin 随机轮询算法，在 分片 以及其所有 副本 中随机选择一个，让读请求负载均衡）。
  3. 接收请求的 node 返回 document 给 协调节点，协调节点返回数据给客户端。


- __ES搜索数据流程__
  1. 客户端发送请求到一个 coordinate node。
  2. 协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以
  3. query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点,进行数据的合并、排序、分页等操作，产出最终结果。
  4. fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端



### 9.4、检索

- filter

- match

### 9.5、score计算

- score


### 9.6、ES的性能优化
> es 性能优化是没有什么银弹的，啥意思呢？就是不要期待着随手调一个参数，就可以万能的应对所有的性能慢的场景。也许有的场景是你换个参数，或者调整一下语法，就可以搞定，但是绝对不是所有场景都可以这样。
- __filesystem cache__
  - 往 es 里写的数据，实际上都写到磁盘文件里去了，查询的时候，操作系统会将磁盘文件里的数据自动缓存到 filesystem cache 里面去。
  - es 的搜索引擎严重依赖于底层的 filesystem cache，你如果给 filesystem cache 更多的内存，尽量让内存可以容纳所有的 idx segment file 索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。
  - __归根结底，你要让 es 性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半。__

- __存储关键字段，结合数据库进行查询__
  - 比如说你现在有一行数据。id,name,age .... 30 个字段。但是你现在搜索，只需要根据 id,name,age 三个字段来搜索。如果你傻乎乎往 es 里写入一行数据所有的字段，就会导致说 90% 的数据是不用来搜索的，结果硬是占据了 es 机器上的 filesystem cache 的空间，单条数据的数据量越大，就会导致 filesystem cahce 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的少数几个字段就可以了，比如说就写入 es id,name,age 三个字段，然后你可以把其他的字段数据存在 mysql/hbase 里，我们一般是建议用 es + hbase 这么一个架构。

- __数据预热__
  - 哪怕是你就按照上述的方案去做了，es 集群中每个机器写入的数据量还是超过了 filesystem cache 一倍，比如说你写入一台机器 60G 数据，结果 filesystem cache 就 30G，还是有 30G 数据留在了磁盘上。

  - 其实可以做数据预热。

  - 举个例子，拿微博来说，你可以把一些大V，平时看的人很多的数据，你自己提前后台搞个系统，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 filesystem cache 里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。

  - 或者是电商，你可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 filesystem cache 里去。

  - 对于那些你觉得比较热的、经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据每隔一段时间，就提前访问一下，让数据进入 filesystem cache 里面去。这样下次别人访问的时候，性能一定会好很多。

- __冷热分离__
  - es 可以做类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在 filesystem os cache 里，别让冷数据给冲刷掉。

  - 你看，假设你有 6 台机器，2 个索引，一个放冷数据，一个放热数据，每个索引 3 个 shard。3 台机器放热数据 index，另外 3 台机器放冷数据 index。然后这样的话，你大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 filesystem cache 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据，也无所谓了。

- __document 模型设计__
  - 对于 MySQL，我们经常有一些复杂的关联查询。在 es 里该怎么玩儿，es 里面的复杂的关联查询尽量别用，一旦用了性能一般都不太好。
  - 最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 es 中。搜索的时候，就不需要利用 es 的搜索语法来完成 join 之类的关联搜索了。

- __分页性能优化__
  es 的分页是较坑的，为啥呢？举个例子吧，假如你每页是 10 条数据，你现在要查询第 100 页，实际上是会把每个 shard 上存储的前 1000 条数据都查到一个协调节点上，如果你有个 5 个 shard，那么就有 5000 条数据，接着协调节点对这 5000 条数据进行一些合并、处理，再获取到最终第 100 页的 10 条数据。
  - 不允许深度分页（默认深度分页性能很差）
  - 类似于 app 里的推荐商品不断下拉出来一页一页的,你可以用 scroll api
    - scroll 会一次性给你生成所有数据的一个快照，然后每次滑动向后翻页就是通过游标 scroll_id 移动，获取下一页下一页这样子，性能会比上面说的那种分页性能要高很多很多，基本上都是毫秒级的。

    - 但是，唯一的一点就是，这个适合于那种类似微博下拉翻页的，不能随意跳到任何一页的场景。也就是说，你不能先进入第 10 页，然后去第 120 页，然后又回到第 58 页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻。

    - 初始化时必须指定 scroll 参数，告诉 es 要保存此次搜索的上下文多长时间。你需要确保用户不会持续不断翻页翻几个小时，否则可能因为超时而失败。

    - 除了用 scroll api，你也可以用 search_after 来做，search_after 的思想是使用前一页的结果来帮助检索下一页的数据，显然，这种方式也不允许你随意翻页，你只能一页页往后翻。初始化时，需要使用一个唯一值的字段作为 sort 字段。


### 9.7、生产部署
- es 生产集群我们部署了 5 台机器，每台机器是 6 核 64G 的，集群总内存是 320G。
- 我们 es 集群的日增量数据大概是 2000 万条，每天日增量数据大概是 500MB，每月增量数据大概是 6 亿，15G。目前系统已经运行了几个月，现在 es 集群里数据总量大概是 100G 左右。
- 目前线上有 5 个索引（这个结合你们自己业务来，看看自己有哪些数据可以放 es 的），每个索引的数据量大概是 20G，所以这个数据量之内，我们每个索引分配的是 8 个 shard，比默认的 5 个 shard 多了 3 个 shard。


### 9.7、倒排索引



## 十、开发框架

### 10.1、spring
- __常用注解__
- 

### 10.2、mybatis

- __执行过程__


- __一级缓存（sqlsession 级别）__
  > [你真的会用Mybatis的缓存么，不知道原理的话，容易踩坑哦](https://www.jianshu.com/p/c553169c5921)
  - 第一次发出一个查询 sql， sql 查询结果写入 sqlsession 的一级缓存中，缓存使用的数据结构是一个 map。
    - key： MapperID+offset+limit+Sql+所有的入参
    - value：用户信息
  - 同一个 sqlsession 再次发出相同的 sql，就从缓存中取出数据。如果两次中间出现 commit 操作（修改、添加、删除），本 sqlsession 中的一级缓存区域全部清空，下次再去缓存中查询不到所以要从数据库查询， 从数据库查询到再写入缓存。

- __二级缓存（mapper 基本）__
  - 在二级缓存的使用中，一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存是被多个SqlSession共享着的，是一个全局的变量。
  - 当开启缓存后，数据的查询执行的流程就是 二级缓存 -> 一级缓存 -> 数据库。




## 十一、Design Pattern





## 十二、Dev Utils

### 11.1、Git
  - __Git工作流程__
    > [Git 工作流程](http://www.ruanyifeng.com/blog/2015/12/git-workflow.html)
  
    Git 作为一个源码管理系统，不可避免涉及到多人协作。
    协作必须有一个规范的工作流程，让大家有效地合作，使得项目井井有条地发展下去。"工作流程"在英语里，叫做"workflow"或者"flow"，原意是水流，比喻项目像水流那样，顺畅、自然地向前流动，不会发生冲击、对撞、甚至漩涡。
    > 本文的三种工作流程，有一个共同点：都采用"功能驱动式开发"（Feature-driven development，简称FDD）。它指的是，需求是开发的起点，先有需求再有功能分支（feature branch）或者补丁分支（hotfix branch）。完成开发后，该分支就合并到主分支，然后被删除。
    - Git flow
      - 首先，项目存在两个长期分支。主分支master、开发分支develop。
      - 前者用于存放对外发布的版本，任何时候在这个分支拿到的，都是稳定的分布版；后者用于日常开发，存放最新的开发版。其次，项目存在三种短期分支。功能分支（feature branch）补丁分支（hotfix branch）预发分支（release branch）一旦完成开发，它们就会被合并进develop或master，然后被删除。
     
    - Github flow
      - Github flow 是Git flow的简化版，专门配合"持续发布"。它是 Github.com 使用的工作流程。__Github flow 的最大优点就是简单，对于"持续发布"的产品，可以说是最合适的流程。__
      - 它只有一个长期分支，就是master，
      - 第一步：根据需求，从master拉出新分支，不区分功能分支或补丁分支。第二步：新分支开发完成后，或者需要讨论的时候，就向master发起一个pull request（简称PR）。第三步：Pull Request既是一个通知，让别人注意到你的请求，又是一种对话机制，大家一起评审和讨论你的代码。对话过程中，你还可以不断提交代码。第四步：你的Pull Request被接受，合并进master，重新部署后，原来你拉出来的那个分支就被删除。（先部署再合并也可。）

    - Gitlab flow
      - Gitlab flow 是 Git flow 与 Github flow 的综合。它吸取了两者的优点，既有适应不同开发环境的弹性，又有单一主分支的简单和便利。它是 Gitlab.com 推荐的做法。
      - 上游优先：Gitlab flow 的最大原则叫做"上游优先"（upsteam first），即只存在一个主分支master，它是所有其他分支的"上游"。只有上游分支采纳的代码变化，才能应用到其他分支。
      - 对于"持续发布"的项目，它建议在master分支以外，再建立不同的环境分支。比如，"开发环境"的分支是master，"预发环境"的分支是pre-production，"生产环境"的分支是production。开发分支是预发分支的"上游"，预发分支又是生产分支的"上游"。代码的变化，必须由"上游"向"下游"发展。比如，生产环境出现了bug，这时就要新建一个功能分支，先把它合并到master，确认没有问题，再cherry-pick到pre-production，这一步也没有问题，才进入production。只有紧急情况，才允许跳过上游，直接合并到下游分支。

  - __git和svn的区别__
    - Git是分布式的，SVN是集中式的
    - Git把内容按元数据方式存储，而SVN是按文件
    - 分支不同
    - 管理权限不同
    - 检出方式不同

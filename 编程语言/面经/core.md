- [一、JAVA基础](#%e4%b8%80java%e5%9f%ba%e7%a1%80)
- [二、JVM](#%e4%ba%8cjvm)
- [三、DB](#%e4%b8%89db)
  - [3.1、mysql的存储引擎](#31mysql%e7%9a%84%e5%ad%98%e5%82%a8%e5%bc%95%e6%93%8e)
  - [3.2、三范式](#32%e4%b8%89%e8%8c%83%e5%bc%8f)
  - [3.3、索引](#33%e7%b4%a2%e5%bc%95)
  - [3.3、事务](#33%e4%ba%8b%e5%8a%a1)
  - [3.4、SQL优化](#34sql%e4%bc%98%e5%8c%96)
  - [3.5、数据库锁](#35%e6%95%b0%e6%8d%ae%e5%ba%93%e9%94%81)
  - [3.6、分库分表](#36%e5%88%86%e5%ba%93%e5%88%86%e8%a1%a8)
- [四、Kafka](#%e5%9b%9bkafka)
  - [4.1、两种消息模型](#41%e4%b8%a4%e7%a7%8d%e6%b6%88%e6%81%af%e6%a8%a1%e5%9e%8b)
  - [4.2、kafka结构原理](#42kafka%e7%bb%93%e6%9e%84%e5%8e%9f%e7%90%86)
  - [4.2、kafka消费策略](#42kafka%e6%b6%88%e8%b4%b9%e7%ad%96%e7%95%a5)
  - [4.3、kafka扩容，重新分区](#43kafka%e6%89%a9%e5%ae%b9%e9%87%8d%e6%96%b0%e5%88%86%e5%8c%ba)
  - [4.5、性能优化](#45%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96)
- [五、RabbitMQ](#%e4%ba%94rabbitmq)
  - [5.1、结构原理](#51%e7%bb%93%e6%9e%84%e5%8e%9f%e7%90%86)
  - [5.2、消息调度策略](#52%e6%b6%88%e6%81%af%e8%b0%83%e5%ba%a6%e7%ad%96%e7%95%a5)
  - [5.3、消息确认机制（Message Acknowledgment）](#53%e6%b6%88%e6%81%af%e7%a1%ae%e8%ae%a4%e6%9c%ba%e5%88%b6message-acknowledgment)
  - [5.4、消息分发机制](#54%e6%b6%88%e6%81%af%e5%88%86%e5%8f%91%e6%9c%ba%e5%88%b6)
  - [5.5、持久化 & 死信队列 & 延时队列](#55%e6%8c%81%e4%b9%85%e5%8c%96--%e6%ad%bb%e4%bf%a1%e9%98%9f%e5%88%97--%e5%bb%b6%e6%97%b6%e9%98%9f%e5%88%97)
- [六、Redis](#%e5%85%adredis)
  - [6.1、Reids数据类型](#61reids%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b)
  - [6.2、缓存雪崩 & 缓存穿透 & 缓存击穿](#62%e7%bc%93%e5%ad%98%e9%9b%aa%e5%b4%a9--%e7%bc%93%e5%ad%98%e7%a9%bf%e9%80%8f--%e7%bc%93%e5%ad%98%e5%87%bb%e7%a9%bf)
  - [6.3、双写一致性问题](#63%e5%8f%8c%e5%86%99%e4%b8%80%e8%87%b4%e6%80%a7%e9%97%ae%e9%a2%98)
  - [6.4、分布式锁](#64%e5%88%86%e5%b8%83%e5%bc%8f%e9%94%81)
  - [6.5、延时队列](#65%e5%bb%b6%e6%97%b6%e9%98%9f%e5%88%97)
  - [6.6、Redis持久化](#66redis%e6%8c%81%e4%b9%85%e5%8c%96)
  - [6.7、同步机制](#67%e5%90%8c%e6%ad%a5%e6%9c%ba%e5%88%b6)
  - [6.8、集群高可用](#68%e9%9b%86%e7%be%a4%e9%ab%98%e5%8f%af%e7%94%a8)
  - [6.9、数据淘汰策略（6种）](#69%e6%95%b0%e6%8d%ae%e6%b7%98%e6%b1%b0%e7%ad%96%e7%95%a56%e7%a7%8d)
  - [6.10、Redis与Memcached区别](#610redis%e4%b8%8ememcached%e5%8c%ba%e5%88%ab)
- [七、ZooKeeper](#%e4%b8%83zookeeper)
  - [7.1、结构原理](#71%e7%bb%93%e6%9e%84%e5%8e%9f%e7%90%86)
  - [7.2、选主投票机制](#72%e9%80%89%e4%b8%bb%e6%8a%95%e7%a5%a8%e6%9c%ba%e5%88%b6)
  - [7.3、应用场景](#73%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af)
  - [7.4、](#74)
  - [7.5、](#75)
- [八、分布式](#%e5%85%ab%e5%88%86%e5%b8%83%e5%bc%8f)
- [九、Design Pattern](#%e4%b9%9ddesign-pattern)

## 一、JAVA基础

  - __集合详解：__ 

  - 

## 二、JVM

  - JVM结构

  - 类加载机制

  - 垃圾回收算法

## 三、DB

### 3.1、mysql的存储引擎

  - __InnoDB：__
    - InnoDB 底层存储结构为B+树， B树的每个节点对应innodb的一个page， page大小是固定的，
      一般设为 16k。其中非叶子节点只有键值，叶子节点包含完成数据

    - 适用场景：
      1）经常更新的表，适合处理多重并发的更新请求。
      2）支持事务。
      3）可以从灾难中恢复（通过 bin-log 日志等）。
      4）外键约束。只有他支持外键。
      5）支持自动增加列属性 auto_increment。
  
  - __MyIsam：__
    - MyIASM是 MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，
      因此当 INSERT(插入)或 UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。

    - ISAM 执行读取操作的速度很快，而且不占用大量的内存和存储资源。在设计之初就预想数据组织
      成有固定长度的记录，按顺序存储的。 ---ISAM 是一种静态索引结构。

  - __Memory：__
    - Memory（也叫 HEAP）堆内存：使用存在内存中的内容来创建表。每个 MEMORY 表只实际对应
      一个磁盘文件。 MEMORY 类型的表访问非常得快，因为它的数据是放在内存中的，并且默认使用
      HASH 索引。但是一旦服务关闭，表中的数据就会丢失掉。 Memory 同时支持散列索引和 B 树索
      引， B树索引可以使用部分查询和通配查询，也可以使用<,>和>=等操作符方便数据挖掘，散列索
      引相等的比较快但是对于范围的比较慢很多

  - __Sequence：__

  - __CSV：__

  - __Aria：__

### 3.2、三范式

  - __第一范式：__
    - 表的列的具有原子性,不可再分解，即列的信息，不能分解，通俗理解即一个字段只存储一项信息。

  - __第二范式：__
    - 首先满足第一范式，并且数据库表中的每个实例或行必须可以被惟一地区分。为实现区分通常需要我们设计一个主键来实现(这里的主键不包含业务逻辑)。
    
    - 即满足第一范式前提，当存在多个主键的时候，才会发生不符合第二范式的情况。比如有两个主键，不能存在这样的属性，它只依赖于其中一个主键，这就是不符合第二范式。通俗理解是任意一个字段都只依赖表中的同一个字段。（涉及到表的拆分）
  
  - __第三范式：__
    - 第三范式定义是，满足第二范式，并且表中不包含已在其它表中已包含的非主键字段
    - 表的信息，如果能够被推导出来，就不应该单独的设计一个字段来存放(能尽量外键join就用外键join)。很多时候，我们为了满足第三范式往往会把一张表分成多张表。

### 3.3、索引

### 3.3、事务
事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作， 这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行 。 事务是一个不可分割的工作逻辑单元事务必须具备以下四个属性，简称 ACID 属性：

  - __原子性：__
    - 事务是一个完整的操作。事务的各步操作是不可分的（原子的）；要么都执行，要么都不执行

  - __一致性：__
    - 当事务完成时，数据必须处于一致状态

  - __隔离性：__
    - 对数据进行修改的所有并发事务是彼此隔离的， 这表明事务必须是独立的，它不应以任何方式依赖于或影响其他事务

  - __永久性：__
    - 事务完成后，它对数据库的修改被永久保持，事务日志能够保持事务的永久性

### 3.4、SQL优化

### 3.5、数据库锁

  - __行级锁：__
    - 行级锁是一种排他锁，防止其他事务修改此行；在使用以下语句时， Oracle 会自动应用行级锁：
      1. INSERT、 UPDATE、 DELETE、 SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];
      2. SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新
      3. 使用 COMMIT 或 ROLLBACK 语句释放锁
    - MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
    - 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
    - 由于mysql 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但如果是使用相同的索引键，是会出现锁冲突的
      - a. 使用相同索引键值的冲突
      - b. 使用不同索引键值但是同一行的冲突
      - c. 创建了索引，但使用的是表锁
      > [mysql InnoDB引擎的行锁和表锁](https://blog.csdn.net/qq_23473123/article/details/80069708)  、  [mysql锁——innodb的行级锁](https://www.cnblogs.com/huangfuyuan/p/9510022.html)

  - __表级锁：__
    - 表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分 MySQL 引擎支持。最常使用的 MYISAM 与 INNODB 都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）

  - __间隙锁：__

  - __页级锁：__
    - 页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。 BDB 支持页级锁

  - __死锁：__
    - MyISAM表锁是deadlock free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，当两个事务都需要获得对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。
    - 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200426113818.png)
    
    - 事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。
    
    - 当出现死锁以后，有两种策略：
      1. 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
      2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。减少死锁的主要方向，就是控制访问相同资源的并发事务量。

### 3.6、分库分表

  - __垂直切分：__
    - 将表按照功能模块、关系密切程度划分出来， 部署到不同的库上。例如，我们会建立定义数据库 workDB、商品数据库 payDB、用户数据库 userDB、日志数据库 logDB 等，分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200424180152.png)

  - __水平切分：__
    - 按照规则划分存储，当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，例如 userID 散列，进行划分，然后存储到多个结构相同的表，和不同的库上
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200424180117.png)

## 四、Kafka

### 4.1、两种消息模型

  - __点对点：__


  - __发布订阅：__

### 4.2、kafka结构原理

Kafka 是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由 LinkedIn 公司开发，使用
Scala 语言编写，目前是 Apache 的开源项目。
  - __基础概念：__
    - broker： Kafka 服务器，负责消息存储和转发
    - topic：消息类别， Kafka 按照 topic 来分类消息
    - partition： topic 的分区，一个 topic 可以包含多个 partition， topic 消息保存在各个
  partition 上
    - offset：消息在日志中的位置，可以理解是消息在 partition 上的偏移量，也是代表该消息的
  唯一序号
    - Producer：消息生产者
    - Consumer：消息消费者
    - Consumer Group：消费者分组，每个 Consumer 必须属于一个 group
    - Zookeeper：保存着集群 broker、 topic、 partition 等 meta 数据；另外，还负责 broker 故
  障发现， partition leader 选举，负载均衡等功能

  - __存储原理：__
    - 在Kafka文件存储中，同一个topic下有多个不同partition，每一个partition为一个文件夹，partiton命名规则为topic名称+有序序号，第一个partiton序号从0開始，序号最大值为partitions数量减1。
    - 每一个partion(文件夹)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件里。segment file组成：由2大部分组成。分别为index file和data file，此2个文件一一相应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件。
    - 在partition中怎样通过offset查找message，比如读取offset=368776的message，须要通过以下2个步骤查找。
      - 第一步查找segment file 当中00000000000000000000.index表示最開始的文件，起始偏移量(offset)为0.第二个文件00000000000000368769.index的消息量起始偏移量为368770 = 368769 + 1.相同，第三个文件00000000000000737337.index的起始偏移量为737338=737337 + 1。其它兴许文件依次类推。以起始偏移量命名并排序这些文件，仅仅要依据offset 二分查找文件列表，就能够高速定位到具体文件。 
    当offset=368776时定位到00000000000000368769.index|log

      - 第二步通过segment file查找message 通过第一步定位到segment file，当offset=368776时。依次定位到00000000000000368769.index的元数据物理位置和00000000000000368769.log的物理偏移地址，然后再通过00000000000000368769.log顺序查找直到offset=368776为止。

  - __Kafka高效文件存储设计特点：__

    - Kafka把topic中一个parition大文件分成多个小文件段。通过多个小文件段，就easy定期清除或删除已经消费完文件。降低磁盘占用。

    - 通过索引信息能够高速定位message和确定response的最大大小。

    - 通过index元数据所有映射到memory，能够避免segment file的IO磁盘操作。

    - 通过索引文件稀疏存储，能够大幅降低index文件元数据占用空间大小。

### 4.2、kafka消费策略

### 4.3、kafka扩容，重新分区

### 4.5、性能优化
  - __批量发送__
      - 是提高消息吞吐量重要的方式， Producer 端可以在内存中合并多条消息后， 以一次请求的方式发送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响了消息的实时性，相当于以时延代价，换取更好的吞吐量。
  - __压缩（GZIP 或 Snappy）__
      - Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后，在Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大数据处理上，瓶颈往往体现在网络上而不是 CPU（压缩和解压会耗掉部分 CPU 资源）。


## 五、RabbitMQ

### 5.1、结构原理
  - __架构图__
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200429113107.png)

    一般来说，我们提到消息队列的时候，生产者是与消息队列直接联系的，但 RabbitMQ 在此之上，多做了一层抽象，在生产者与消息队列之前插入了一个交换器（Exchange），从而实现了生产者与消息队列的解耦。

  - __基础概念__
    - Producer 生产者：向消息队列发布消息的客户端应用程序。

    - Channel 信道：多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的 TCP 连接内的虚拟连接，复用 TCP 连接的通道。

    - Exchange 交换器：提供 Producer 到 Queue 之间的匹配，接收生产者发送的消息并将这些消息按照路由规则转发到消息队列。交换器用于转发消息，它不会存储消息 ，若没有 Queue 绑定到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息。

    - Binding 绑定：Binding 用于建立 Exchange 和 Queue 之间的关联。

    - Queue 消息队列：保存消息，直到消息发送给消费者。注意一个消息可投入一个或多个队列。

    - Consumer 消费者：从消息队列取得消息的客户端应用程序。

    - Broker 服务器：RabbitMQ 服务器


### 5.2、消息调度策略

  - __消息调度策略__ 
    指的是在收到生产者发送的消息后，Exchange 根据什么规则将消息转发到队列中。

    RabbitMQ 为我们提供了四种 Exchange，分别是 fanout，direct，topic，header，而 header 模式在实际使用中较少

    - Routing Key：路由键，用于标记消息的路由规则，决定了交换机的转发路径。
    - Binding Key：绑定键，用于匹配 Routing Key，表示 Exchange 与 Queue 的绑定关系。

  - __Fanout__
    Fanout 又被称为订阅/广播模式。该模式模式与 Binding Key 和 Routing Key 无关，Exchange 将接收到的消息分发给所有与该交换器绑定的消息队列。注意，Fanout 转发消息是最快的。

  - __Direct__
    Direct 即是路由模式，也是 Exchange 的默认模式。唯有当 Routing Key 与 Binding Key 完全匹配的时候才将消息发送至消息队列。

    事实上，RabbitMQ 默认提供了一个 Exchange，名字是空字符串，类型是 Direct，绑定到所有的Queue 上（每一个 Queue 和这个无名 Exchange 之间的 Binding Key 是 Queue 的名字）。所以，有时候我们感觉不需要 Exchange 也可以发送和接收消息，实际上是使用了 RabbitMQ 默认提供的 Exchange。

  - __Topic__
    Topic 就是通配符模式。Routing Key 与 Binding Key 会根据正则表达式进行模糊匹配，若匹配成功则会将消息转发至消息队列。

### 5.3、消息确认机制（Message Acknowledgment）
  - 我们现在假设一种情况，消费者刚刚收到消息队列发来的信息，却不幸宕机，导致了信息丢失，这该咋办呢？

  - 其实，这种情况完全可以通过消费者在消费完消息后发送一个回执给 RabbitMQ 解决，这也被称为消息确认机制。RabbitMQ 在收到消费回执之后才将消息移除出消息队列，若没有收到信息回执并检测到消费者的 RabbitMQ 连接断开，那么 RabbitMQ 会将该消息发送给其他消费者进行处理。

  - 需要注意的是，只要消费者的 RabbitMQ 连接没有断开，无论消费者处理消息时间有多长，都不会导致该消息被发送给其他消费者。


### 5.4、消息分发机制

  - __轮询分发__
    - 轮询分发，Round-robin dispatching，也是 RabbitMQ 的默认消息分发机制。队列会给每一个消费者发送的数据数量是一模一样的，并不会因为两个消费者处理数据速度不同而发生改变。这样很容易导致部分消费者天天加班，而部分消费者无所事事的情况。

    - 轮询分发是 RabbitMQ 默认的消息分发机制。

  - __公平分发__
    - 公平分发，Fair dispatch，消费者设置每次从队列里只取一条数据，并且关闭自动回复机制，每次取完一条数据后，手动回复并继续取下一条数据。这样每个消费者都只有消费完一条消息才会收到下一条消息，十分的“公平”。（每个消费者在同一时间点最多处理的消息个数由 prefetchCount 参数规定，而不是固定为1个）

    - 需要注意的是，如果我们使用公平分发，那么必须关闭自动应答，同时改为手动应答。


### 5.5、持久化 & 死信队列 & 延时队列

  - __持久化：__
    - 死信队列，又称 dead-letter-exchange（DLX）。当一条消息在一个队列中变成死信后，它会被重新发布到一个交换机中，这个交换机就是 DLX。

  - __死信队列：__
    - 消息被拒绝（reject ，nack），并且 requeue = false（不再重新投递）
    - 消息 TTL 过期
    - 队列超过最长长度

  - __延时队列：__
    - 我们在网上购物，提交订单之后30分钟内必须付款，否则就会取消订单，这种情况下，我们不可能单单只开启一个异步线程而不做其他处理。在这里，我可以提供一种方案来解决这个问题，那就是使用延时消息队列。在消息发布之后，保存在消息中间件中，延时一段时间之后才会发布至队列中。延时队列监听器在这段时间结束后才能监听到消息并开始执行

    - RabbitMQ 本身并没有直接实现延时队列，但是我们可以使用 RabbitMQ 的属性（TTL，DLX）来模拟一个延时队列。我们可以在消息上设置过期时间，然后在消息队列上为死信指定转发器，这样消息过期后会转发到与指定转发器匹配的死信队列上，从而实现延时队列。







## 六、Redis

### 6.1、Reids数据类型
  - __String：__
    - 这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。
    - 许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。例如秒杀场景
    - 共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie，但是可以利用Redis将用户的Session集中管理，在这种模式只需要保证Redis的高可用，每次用户Session的更新和获取都可以快速完成。大大提高效率
  
  - __Hash：__
    - 类似 Map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段
    - 做数据字典使用
    - Redis 中的 Hash和 Java的 HashMap 比较相似,都是数组+链表的结构.当发生 hash 碰撞时将会把元素追加到链表上.值得注意的是在 Redis 的 Hash 中 value 只能是字符串。在 Java 中 HashMap 扩容是个很耗时的操作,需要去申请新的数组,为了追求高性能,Redis 采用了渐进式 rehash 策略.这也是 hash 中最重要的部分。
      ```
      a. Redis是在插入新节点之前判断是否需要进行扩容，如果不需要，则直接插入，否则需要先扩容，再插入新节点。
      b. 在扩容的时候 rehash 策略会保留新旧两个 hashtable 结构,查询时也会同时查询两个 hashtable.Redis会将旧 hashtable 中的内容一点一点的迁移到新的 hashtable 中,当迁移完成时,就会用新的 hashtable 取代之前的.当 hashtable 移除了最后一个元素之后,这个数据结构将会被删除
      c. 服务器目前没有在执行BGSAVE命令或者BGREWRITEAPF命令，并且 哈希表保存的key的数量 / 哈希表的大小>=1；
         服务器目前正在执行BGSAVE命令或者BGREWRITEAPF命令，并且 哈希表保存的key的数量 / 哈希表的大小>=5;
      d. 因为在rehash的过程中，字典会同时使用两个哈希表，所以在rehash期间，字典的删除、查找、更新、增加等操作会在两个哈希表中进行
      e. 渐进式rehash避免了redis阻塞（原来进行一次put操作，要等到rehash全部结束，这个操作才会返回，现在则只需要辅助rehash一步），但是由于在rehash时，需要分配一个新的hash表，在rehash期间，同时有两个hash表在使用，会使得redis内存使用量瞬间突增，在Redis 满容状态下由于Rehash会导致大量Key驱逐
      ```


  
  - __List：__
    - List 是有序列表，可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。
    - 可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走
    - 可以搞个简单的消息队列，从 List 头怼进去，从 List 屁股那里弄出来
  
  - __Set：__
    - Set 是无序集合，会自动去重
  
  - __SortSet：__
    - 是排序的 Set，去重但可以排序，每个元素都会关联一个double类型的分数。通过分数来为集合中的成员进行从小到大的排序
    - 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。
    - 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。
    - 可用来做延时队列
  
  - __HyperLogLog：__
    - Redis 在 2.8.9 版本添加了 HyperLogLog 结构。用来做基数统计,在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。
    - 每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数
    - 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

  - __Geo：__
    - GEO功能在Redis3.2版本提供，支持存储地理位置信息，用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能.geo的数据类型为zset
  
  - __Pub/Sub：__
    - 发布订阅模式，做简单的消息中间件，缺点是消息无法持久化，消费者掉线中，此时生产者有新消息产生后会丢失。
    - 订阅发布可以支持多客户端获取同一个频道发布的消息，当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的所有客户端。
  
  - __BloomFilter：__
    - 布隆过滤器，解决缓存穿透问题
  
  - __RedisSearch：__
    - 全文检索功能服务

### 6.2、缓存雪崩 & 缓存穿透 & 缓存击穿

  - __缓存雪崩：__

    - 目前电商首页以及热点数据都会去做缓存 ，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题  

    - a. 处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效，我相信，Redis这点流量还是顶得住的。setRedis（Key，value，time + Math.random() * 10000）；

    - b. 或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险  

  - __缓存穿透：__
    
    - 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库  

    - 在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return
  
    - 布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。


  - __缓存击穿：__

    - 至于缓存击穿嘛，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞

    - 设置热点数据永远不过期。或者加上互斥锁就能搞定了。


### 6.3、双写一致性问题

  - __概念描述：__
    数据库里的值和缓存中的数据不一致的现象就叫做  数据库和缓存双写一致性问题
      - 在高并发的情况下很难去保证数据库和缓存的数据永远一致，我们只能去确保最终一致性。

  - __常用解决方案：__
    - a. 给缓存设置失效时间
      - 统一要求当缓存失效时再去数据库中查数据更新缓存
    - b. 先更新数据库，再删缓存的策略（Cache Aside Pattern）
      标准的Pattern，facebook就是使用这种方式，具体流程如下：
      - 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
      - 命中：应用程序从cache中取数据，取到后返回。
      - 更新：先把数据存到数据库中，成功后，再让缓存失效。
    - c. 先删除缓存，再更新数据库策略

  - __最佳方案：__
    - 给缓存设置失效时间，达成最终一致性
    - Cache Aside Pattern方案



### 6.4、分布式锁

### 6.5、延时队列

使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

- __延时队列的应用场景__
  - 订单：比如电商业务，提交订单之后30分钟内未完成付款将取消订单
  - 通知：在任务完成后的一段时间给用户发送通知
  - 重试：业务操作失败后，间隔一段时间后进行失败重试

- __RabbitMQ的死信队列也可实现延时队列__

- __延时队列相对于定时扫描的优点__
  - 定时扫描数据量过大时会消耗太多的IO资源，效率太低
  - 定时扫描有一定的时间差

### 6.6、Redis持久化

- __RDB：__ RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化

- __AOF：__ AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的binlog

### 6.7、同步机制

### 6.8、集群高可用

### 6.9、数据淘汰策略（6种）
Redis可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。
  - __volatile-lru：__
    - 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
  - __volatile-ttl：__
    - 从已设置过期时间的数据集中挑选将要过期的数据淘汰
  - __volatile-random：__
    - 从已设置过期时间的数据集中任意选择数据淘汰
  - __allkeys-lru：__
    - 从所有数据集中挑选最近最少使用的数据淘汰
  - __allkeys-random：__
    - 从所有数据集中任意选择数据进行淘汰
  - __noeviction：__
    - 禁止驱逐数据


### 6.10、Redis与Memcached区别


|     |redis  |Memcached|
|-----|------|--------|
| 数据类型| Redis 支持五种不同的数据类型，可以更灵活地解决问题|仅支持字符串类型|
|数据持久化|Redis 支持两种持久化策略：RDB 快照和 AOF 日志| Memcached 不支持持久化|
|分布式|Redis Cluster 实现了分布式的支持|Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。|
|内存管理机制|在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。|Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。|




## 七、ZooKeeper

### 7.1、结构原理

  - __存储结构图__
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200429162023.png)
    - /master：存储主节点的信息，若在主从模式中其没有数据，代表分布式应用的主节点还没有被选举出来。
    - /workers：下面的每个子 znode 代表一个从节点。
    - /tasks：下面的每个子 znode 代表一个任务，znode 上存储的信息代表着任务内容。
    - /assign：下面每个子 znode 代表一个从节点的任务集合。/assign/worker-1 代表从节点 worker-1 的任务集合，其下面的子 znode 都是分配给 worker-1 的任务。

  - __ZK角色__
    - leader：领导者。leader 作为整个 ZooKeeper 集群的主节点，负责响应所有对 ZooKeeper
    状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个集群内部消息处理的FIFO 。eader 为客户端提供读和写服务。

    - follower：追随者。follower 除了需要响应本服务器上的读请求外，还要处理 leader 的提议，并在 leader 提交提议时在本地也进行提交。需要注意的是，leader 和 follower 共同构成了 ZooKeeper 集群的法定人数，也就是说，只有他们才参与新 leader 的选举、响应 leader 的提议。

    - observer：观察者。若 ZooKeeper 集群的读取负载很高，可以设置一些 observer 服务器，以提高读取的吞吐量。observer 和 follower 比较相似，但还是具有两个区别：一是 observer 不属于法定人数，即不参加选举也不响应提议；二是 observer 不需要将事务持久化到磁盘，一旦 observer 被重启，需要从 leader 重新同步整个名字空间。需要注意，一个 ZooKeeper 集群同一时刻只会有一个 Leader，其他都是 Follower 或 Observer。


### 7.2、选主投票机制

- __ZAB协议：__
  - Zab 协议有两种模式：Zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态

- __选主流程：__

  目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
  1. 服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反
  馈信息，服务器 1 的状态一直属于 Looking。
  2. 服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号
  大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是
  LOOKING。
  3. 服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编
  号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器
  1,2 成为小弟。
  4. 服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的
  编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。
  5. 服务器 5 启动，后面的逻辑同服务器 4 成为小弟


### 7.3、应用场景
- __分布式协调__
- __分布式锁__
- __元数据/配置信息管理__
- __HA高可用性__


### 7.4、


### 7.5、



## 八、分布式

## 九、Design Pattern


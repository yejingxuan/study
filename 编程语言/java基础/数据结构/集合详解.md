# JAVA集合详解

> 参考文章:  
[Java面试中碰到集合问题，看这篇就够了](https://www.toutiao.com/i6657333580445778435/)  
[HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！](https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/)  
[Java学习+面试指南](https://github.com/Snailclimb/JavaGuide?tdsourcetag=s_pctim_aiomsg)


## 一、List集合

### 1. ArrayList

|       |ArrayList|LinkedList|Vector|
|:-----:|:-------:|:--------:|:----:|
|实现原理|Object动态数组|双向链表|Object动态数组(同ArrayList)|
|线程安全|否|否|是|
|插入速度|慢|快|慢|
|查询速度|快|慢|快|

- 实现原理

    ArrayList是List接口的实现类，插入的元素是有序的，其顺序就是插入时的先后顺序，__ArrayList底层实现为动态数组__，默认大小为10，每次添加元素时会检查容量是否超过出示容量，如果超出则进行扩容（int newCapacity = (oldCapacity * 3)/2 + 1;）

    ArrayList底层实现是数组，所以我们如果知道元素的下标，那么就能很快的定位到相关元素，所以其查询性能高，但是添加会涉及到数组中其他元素的移动，所以性能不佳。

- 选择场景 

    所以在使用ArrayList的时候，如果可以尽量估算一个初始容量，减少扩容频率，同时尽量将ArrayList用于查询操作多余添加操作的集合

    ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e) 方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element) ）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作

### 2. Vector

- Vector同样实现了List接口，__Vector与ArrayList的底层实现是一样的，只不过Vector是ArrayList的线程安全版本__，因为Vector采用synchronize关键字修饰所有方法，在多线程环境下，只有一个线程能够操作Vector，但是如果存在线程安全问题的话Vector的效率要低于ArrayList，因为Vector会涉及到获取锁和释放锁

### 3. LinkedList

- LinkedList同样实现了List接口，插入元素的仍然是有序，其顺序就是插入时的先后顺序，__LinkedList底层是以双向链表的结构实现的（JDK1.6之前为循环链表，JDK1.7取消了循环。注意双向链表和双向循环链表的区别：）__，链表的特点就是在内存中不是连续的内存分布，而是通过指针相连，所以其查找速度不如ArrayList，但是由于链表不是连续的，所以其添加和删除的性能要优于ArrayList，因为我们添加和删除元素不会涉及到其他元素的移动。

- LinkedList 采用链表存储，所以插入，删除元素时间复杂度不受元素位置的影响，都是近似 O（1）而数组为近似 O（n）。





---


## 二、Set集合

### 1. HashSet

- HashSet是Set接口的实现类，Set接口的实现类，不允许元素的重复，HashSet的底层实现是基于HashMap实现的，只不过HashSet只使用了HashMap的key部分而已，HashMap的Value部分被一个统一个Object对象代替，HashSet是基于Hash算法实现，所以我们在使用HashSet作为容器是，我们添加的元素需要重写hashCode和equals方法，HashSet集合允许一个key为null


### 2. LinkedHashSet

- LinkedHashSet集合同样是根据元素的hashCode值来决定元素的存储位置，但是它同时使用链表维护元素的次序。这样使得元素看起 来像是以插入顺序保存的，也就是说，当遍历该集合时候，LinkedHashSet将会以元素的添加顺序访问集合的元素

### 3. TreeSet

- TreeSet是基于TreeMap实现的。TreeSet中的元素支持2种排序方式：自然排序 或者 根据创建TreeSet 时提供的 Comparator 进行排序。这取决于使用的构造方法

- TreeSet的本质是一个"有序的，并且没有重复元素"的集合，它是通过TreeMap实现的。TreeSet中含有一个NavigableMap类型的成员变量m，而m实际上是TreeMap的实例。





## 三、Map集合

|       |HashMap|HashTable|ConcurrentHashMap|
|:-----:|:-------:|:--------:|:----:|
|实现原理|数组+链表/红黑二叉树|数组+链表|数组+链表/红黑二叉树|
|是否有null的key|是|否|是|
|线程安全|否|是|是|
|插入速度|快|慢|稍快|

### 1. HashMap

- 实现原理

  1. HashMap是Map接口的实现，Map接口的特点就是以Key-Value的形式存储数据，HashMap底层是通过数组加链表的形式基于Hash算法实现的，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话， 需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。  

  2. jdk1.8之后hashmap改为数组+链表+红黑树的结构，当链表中的元素超过了 8 个以后，
    会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。
    ![](https://gitee.com/jingxuanye/yjx-pictures/raw/master/pic/20200413103355.png)
    每个绿色的实体是嵌套类 Entry 的实例， Entry 包含四个属性： key, value, hash 值和用于单向链表的 next。

- hashmap扩容
  1. 当hashmap中的元素越来越多的时候，碰撞的几率也就越来越高（因为数组的长度是固定的），所以为了提高查询的效率，就要对hashmap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，所以这是一个通用的操作，很多人对它的性能表示过怀疑，不过想想我们的“均摊”原理，就释然了，而在hashmap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize
   
  2. 默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中
      - capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。
      - loadFactor：负载因子，默认为 0.75。13/04/2018 Page 51 of 283
      - hreshold：扩容的阈值，等于 capacity * loadFactor  
  
  3. Resize步骤
       - 扩容：创建一个新的Entry空数组，长度是原数组的2倍。
       - ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组。为什么要重新Hash呢？因为长度扩大以后，Hash的规则也随之改变。
       - hash公式：index = HashCode（Key） & （Length - 1）

  4. 默认情况下HashMap的容量是16，但是，如果用户通过构造函数指定了一个数字作为容量，那么Hash会选择大于该数字的第一个2的幂作为容量。(3->4、7->8、9->16)。设置16是因为是2的幂，符合内部计算的机制，而且这个值，不大也不小，太小了就有可能频繁发生扩容，影响效率。太大了又浪费空间。而加载因子0.75的是为了提高空间利用率和减少查询成本的折中，0.75的话碰撞最小


### 2. ConcurrentHashMap

- 实现原理
  1. ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。整个 ConcurrentHashMap 由一个个 Segment 组成， Segment 代表”部分“或”一段“的
  意思，所以很多地方都会将其描述为分段锁。

  2. 简单理解就是， ConcurrentHashMap 是一个 Segment 数组， Segment 通过继承
  ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。

  3. concurrencyLevel：并行级别、并发数、 Segment 数，怎么翻译不重要，理解它。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上， 这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些

### 3. HashTable

- 实现原理
  1. HashTable同样是基于Map实现的Key-Value形式存的数据结构，与HashMap不同的是，HashTable中所有的方法都是有synchronize关键字进行修饰的，即，HashTable是HashMap的线程安全版，但是在非线程安全的场景下HashTable的性能比HashMap的要低，因为会涉及到获取锁和释放锁的过程。

  2. Hashtable 是遗留类，很多映射的常用功能与 HashMap 类似，不同的是它承自 Dictionary 类，并且是线程安全的，任一时间只有一个线程能写 Hashtable，并发性不如 ConcurrentHashMap，因为 ConcurrentHashMap 引入了分段锁。 Hashtable 不建议在新代码中使用，不需要线程安全的场合可以用 HashMap 替换，需要线程安全的场合可以用 ConcurrentHashMap 替换。

### 3. LinkedHashMap

- 实现原理

    LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑
    


    



